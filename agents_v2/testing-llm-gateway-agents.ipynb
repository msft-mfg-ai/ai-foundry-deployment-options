{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Agents v2 in AI Foundry\n",
    "This notebook creates and runs an agent from AI Foundry\n",
    "\n",
    "Best way to set it up is with [uv](https://docs.astral.sh/uv/)\n",
    "\n",
    "1. in `agents` directory run `uv sync` (if python is missing, install it using `uv python install`)\n",
    "2. in VSCode press [Ctrl+Shift+P] and select `Python: Select Interpreter`, choose the one from `agents` directory: `./agents/.venv/bin/python3.xx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Create Project client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import atexit\n",
    "import jsonref\n",
    "import os\n",
    "from azure.identity.aio import DefaultAzureCredential, AzureDeveloperCliCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    MCPTool,\n",
    "    Tool,\n",
    ")\n",
    "from openai import AsyncOpenAI\n",
    "from openai.types.responses.response_input_param import (\n",
    "    McpApprovalResponse,\n",
    "    ResponseInputParam,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "from src.agents_utils import agents_utils\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "print(\"ðŸš€ Initializing AI Foundry Agent Testing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_AI_FOUNDRY_CONNECTION_STRING\")\n",
    "deployment_name = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\", None)\n",
    "tenant_id = os.environ.get(\"AZURE_TENANT_ID\", None)\n",
    "\n",
    "print(\"\\nðŸ“‹ Configuration:\")\n",
    "print(f\"   ðŸ“ Endpoint: {endpoint[:50]}...\" if endpoint else \"   âš ï¸ Endpoint: Not set\")\n",
    "print(f\"   ðŸ¤– Model: {deployment_name}\" if deployment_name else \"   âš ï¸ Model: Not set\")\n",
    "print(f\"   ðŸ“¦ API Version: {api_version or 'Default'}\")\n",
    "\n",
    "ai_agent_settings = {\n",
    "    \"endpoint\": endpoint,\n",
    "    \"model_deployment_name\": deployment_name,\n",
    "    \"api_version\": api_version,\n",
    "}\n",
    "\n",
    "# Setup credentials\n",
    "print(\"\\nðŸ” Setting up authentication...\")\n",
    "if os.environ.get(\"USE_AZURE_DEV_CLI\") == \"true\":\n",
    "    print(\"   âœ… Using Azure Developer CLI Credential\")\n",
    "    creds = AzureDeveloperCliCredential(tenant_id=tenant_id)\n",
    "else:\n",
    "    print(\"   âœ… Using Default Azure Credential\")\n",
    "    creds = DefaultAzureCredential()\n",
    "\n",
    "await creds.__aenter__()\n",
    "print(\"   ðŸ”“ Credentials initialized successfully!\")\n",
    "\n",
    "# Initialize clients\n",
    "print(\"\\nðŸ”§ Initializing clients...\")\n",
    "client = AIProjectClient(endpoint=endpoint, credential=creds)\n",
    "await client.__aenter__()\n",
    "agents_client = agents_utils(client)\n",
    "print(\"   âœ… AI Project Client ready\")\n",
    "print(\"   âœ… Agents Client ready\")\n",
    "\n",
    "# List connections\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ”— AVAILABLE CONNECTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model_gateway_connection_static = None\n",
    "model_gateway_connection_dynamic = None\n",
    "ai_gateway_connection_static = None\n",
    "ai_gateway_connection_dynamic = None\n",
    "\n",
    "connection_count = 0\n",
    "async for connection in client.connections.list():\n",
    "    connection_count += 1\n",
    "    icon = (\n",
    "        \"ðŸŒ\"\n",
    "        if connection.type == \"ModelGateway\"\n",
    "        else \"ðŸ”Œ\" if connection.type == \"ApiManagement\" else \"ðŸ“¡\"\n",
    "    )\n",
    "    default_badge = \" â­ DEFAULT\" if connection.is_default else \"\"\n",
    "    print(f\"\\n{icon} {connection.name}{default_badge}\")\n",
    "    print(f\"   Type: {connection.type}\")\n",
    "    print(f\"   ID: {connection.id[:50]}...\")\n",
    "\n",
    "    if connection.type == \"ModelGateway\" and \"static\" in connection.name.lower():\n",
    "        model_gateway_connection_static = connection.name\n",
    "        print(\"   ðŸ“Œ â†’ Assigned to: model_gateway_connection_static\")\n",
    "    if connection.type == \"ModelGateway\" and \"static\" not in connection.name.lower():\n",
    "        model_gateway_connection_dynamic = connection.name\n",
    "        print(\"   ðŸ“Œ â†’ Assigned to: model_gateway_connection_dynamic\")\n",
    "    if connection.type == \"ApiManagement\" and \"static\" in connection.name.lower():\n",
    "        ai_gateway_connection_static = connection.name\n",
    "        print(\"   ðŸ“Œ â†’ Assigned to: ai_gateway_connection_static\")\n",
    "    if connection.type == \"ApiManagement\" and \"static\" not in connection.name.lower():\n",
    "        ai_gateway_connection_dynamic = connection.name\n",
    "        print(\"   ðŸ“Œ â†’ Assigned to: ai_gateway_connection_dynamic\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Total connections found: {connection_count}\")\n",
    "\n",
    "# List agents\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ¤– EXISTING AGENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "agents = await agents_client.get_agents()\n",
    "if agents:\n",
    "    for agent in agents:\n",
    "        print(f\"\\nðŸ¤– {agent.name}\")\n",
    "        print(f\"   ID: {agent.id}\")\n",
    "        print(f\"   Version: {agent.versions.latest.version}\")\n",
    "else:\n",
    "    print(\"\\n   â„¹ï¸ No agents found in this project\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… SETUP COMPLETE - Connection Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(\n",
    "    f\"   ðŸŒ Model Gateway (Static):  {'âœ… ' + model_gateway_connection_static if model_gateway_connection_static else 'âŒ Not found'}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ðŸŒ Model Gateway (Dynamic): {'âœ… ' + model_gateway_connection_dynamic if model_gateway_connection_dynamic else 'âŒ Not found'}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ðŸ”Œ AI Gateway (Static):     {'âœ… ' + ai_gateway_connection_static if ai_gateway_connection_static else 'âŒ Not found'}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ðŸ”Œ AI Gateway (Dynamic):    {'âœ… ' + ai_gateway_connection_dynamic if ai_gateway_connection_dynamic else 'âŒ Not found'}\"\n",
    ")\n",
    "print(\"\\nðŸŽ‰ Ready to run agent tests!\")\n",
    "\n",
    "\n",
    "async def cleanup():\n",
    "    \"\"\"Close all async clients properly\"\"\"\n",
    "    try:\n",
    "        await client.close()\n",
    "    except Exception:\n",
    "        await client.__aexit__(None, None, None)\n",
    "    try:\n",
    "        await creds.close()\n",
    "    except Exception:\n",
    "        await creds.__aexit__(None, None, None)\n",
    "    print(\"ðŸ§¹ Clients closed\")\n",
    "\n",
    "\n",
    "def sync_cleanup():\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            loop.create_task(cleanup())\n",
    "        else:\n",
    "            loop.run_until_complete(cleanup())\n",
    "    except Exception:\n",
    "        print(\"âš ï¸ Cleanup failed\")\n",
    "        pass\n",
    "\n",
    "\n",
    "atexit.register(sync_cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple requests for each gateway connection and capture request IDs\n",
    "import pandas as pd\n",
    "from openai import APIStatusError, APIError\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "print(\"ðŸ§ª GATEWAY CONNECTION TESTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing each gateway connection with multiple requests to verify\")\n",
    "print(\"connectivity and capture request IDs for debugging.\\n\")\n",
    "\n",
    "# Collect all gateway connections to test\n",
    "gateway_connections = {\n",
    "    \"model_gateway_static\": model_gateway_connection_static,\n",
    "    \"model_gateway_dynamic\": model_gateway_connection_dynamic,\n",
    "    \"ai_gateway_static\": ai_gateway_connection_static,\n",
    "    \"ai_gateway_dynamic\": ai_gateway_connection_dynamic,\n",
    "}\n",
    "deployment_model: str = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Filter out None connections\n",
    "active_connections = {k: v for k, v in gateway_connections.items() if v is not None}\n",
    "print(f\"ðŸ“Š Found {len(active_connections)} active connections to test:\")\n",
    "for name in active_connections.keys():\n",
    "    print(f\"   â€¢ {name}\")\n",
    "\n",
    "results = []\n",
    "num_requests = 20\n",
    "delete_agent_before_create = False\n",
    "\n",
    "print(f\"\\nâš™ï¸ Test Configuration:\")\n",
    "print(f\"   â€¢ Requests per connection: {num_requests}\")\n",
    "print(f\"   â€¢ Model: {deployment_model}\")\n",
    "print(f\"   â€¢ Delete agent before create: {delete_agent_before_create}\")\n",
    "\n",
    "for conn_name, conn_value in active_connections.items():\n",
    "    print(f\"\\n{'â”€' * 60}\")\n",
    "    print(f\"ðŸ”„ Testing: {conn_name}\")\n",
    "    print(f\"   Connection: {conn_value}\")\n",
    "    print(f\"{'â”€' * 60}\")\n",
    "\n",
    "    for i in range(num_requests):\n",
    "        request_id = None\n",
    "        result = None\n",
    "        error_msg = None\n",
    "\n",
    "        try:\n",
    "            agent_name = f\"TestAgent_{conn_name}\".replace(\" \", \"-\").replace(\"_\", \"-\")[\n",
    "                :63\n",
    "            ]\n",
    "\n",
    "            # Create agent for this connection\n",
    "            print(f\"   ðŸ“ Request {i+1}/{num_requests}: Creating agent...\", end=\" \")\n",
    "            agent = await agents_client.create_agent(\n",
    "                name=agent_name,\n",
    "                model_gateway_connection=conn_value,\n",
    "                deployment_name=deployment_model,\n",
    "                delete_before_create=delete_agent_before_create,\n",
    "            )\n",
    "\n",
    "            openai_client = client.get_openai_client()\n",
    "\n",
    "            # Create conversation\n",
    "            conversation = await openai_client.conversations.create(\n",
    "                items=[\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"What is 2 + {i}? Reply with just the number.\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # Get response\n",
    "            response = await openai_client.responses.create(\n",
    "                conversation=conversation.id,\n",
    "                extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "                input=\"\",\n",
    "            )\n",
    "\n",
    "            # Extract request ID from response\n",
    "            request_id = response._request_id\n",
    "            result = \"SUCCESS\"\n",
    "            output = response.output_text[:50] if response.output_text else \"No output\"\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Connection\": conn_name,\n",
    "                    \"Model\": deployment_model,\n",
    "                    \"Request #\": i + 1,\n",
    "                    \"Request ID\": request_id,\n",
    "                    \"Result\": result,\n",
    "                    \"Output\": output,\n",
    "                }\n",
    "            )\n",
    "            print(f\"âœ… SUCCESS\")\n",
    "            print(f\"      Response: {output}\")\n",
    "            print(f\"      Request ID: {request_id}\")\n",
    "\n",
    "        except (APIStatusError, APIError, HttpResponseError) as e:\n",
    "            request_id = (\n",
    "                e.response.headers.get(\"x-request-id\", \"N/A\")\n",
    "                if hasattr(e, \"response\")\n",
    "                else \"N/A\"\n",
    "            )\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Connection\": conn_name,\n",
    "                    \"Model\": deployment_model,\n",
    "                    \"Request #\": i + 1,\n",
    "                    \"Request ID\": request_id,\n",
    "                    \"Result\": result,\n",
    "                    \"Output\": error_msg,\n",
    "                }\n",
    "            )\n",
    "            print(f\"âŒ ERROR\")\n",
    "            print(f\"      {error_msg}\")\n",
    "            print(f\"      Request ID: {request_id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Connection\": conn_name,\n",
    "                    \"Model\": deployment_model,\n",
    "                    \"Request #\": i + 1,\n",
    "                    \"Request ID\": \"N/A\",\n",
    "                    \"Result\": result,\n",
    "                    \"Output\": error_msg,\n",
    "                }\n",
    "            )\n",
    "            print(f\"âŒ ERROR\")\n",
    "            print(f\"      {error_msg}\")\n",
    "\n",
    "# Create DataFrame and display results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“Š RESULTS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "csv_file = \"gateway_connection_test_results.csv\"\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"\\nðŸ’¾ Results saved to: {csv_file}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“ˆ SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "summary = df.groupby([\"Connection\", \"Result\"]).size().unstack(fill_value=0)\n",
    "print(summary)\n",
    "\n",
    "# Calculate success rate\n",
    "total = len(results)\n",
    "successes = len([r for r in results if r[\"Result\"] == \"SUCCESS\"])\n",
    "success_rate = (successes / total * 100) if total > 0 else 0\n",
    "print(f\"\\nðŸŽ¯ Overall Success Rate: {successes}/{total} ({success_rate:.1f}%)\")\n",
    "\n",
    "if success_rate == 100:\n",
    "    print(\"ðŸŽ‰ All tests passed!\")\n",
    "elif success_rate >= 50:\n",
    "    print(\"âš ï¸ Some tests failed - check the results above\")\n",
    "else:\n",
    "    print(\"âŒ Most tests failed - investigate connection issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Foundry directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”— DIRECT FOUNDRY CALL\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Calling AI Foundry directly without agent abstraction\")\n",
    "print(f\"   ðŸ“ Connection: {model_gateway_connection_static}\")\n",
    "print(f\"   ðŸ¤– Model: {deployment_name}\")\n",
    "print()\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    model=f\"{model_gateway_connection_static}/{deployment_name}\",\n",
    "    input=\"I am going to Paris, what should I see? Keep your answer brief.\",\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Response received!\")\n",
    "print(f\"   ðŸ†” Request ID: {response._request_id}\")\n",
    "print(\"\\nðŸ’¬ Response:\")\n",
    "print(\"â”€\" * 40)\n",
    "print(response.output_text)\n",
    "print(\"â”€\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run agent using static gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ¤– AGENT WITH STATIC GATEWAY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   ðŸ”— Connection: {ai_gateway_connection_static}\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ“ Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyV2Agent\",\n",
    "    model_gateway_connection=ai_gateway_connection_static,\n",
    "    delete_before_create=True,\n",
    ")\n",
    "print(f\"   âœ… Agent created: {agent.name}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the size of Poland in square miles?\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"   ðŸ’¬ Conversation started: {conversation.id[:20]}...\")\n",
    "\n",
    "print(\"\\nâ³ Waiting for response...\")\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Response received!\")\n",
    "print(f\"   ðŸ†” Response ID: {response.id}\")\n",
    "print(\"\\nðŸ’¬ Output:\")\n",
    "print(\"â”€\" * 40)\n",
    "print(response.output_text)\n",
    "print(\"â”€\" * 40)\n",
    "print(f\"\\nðŸ’° Usage: {response.to_dict()['usage']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run agent using dynamic gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ¤– AGENT WITH DYNAMIC GATEWAY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   ðŸ”— Connection: {model_gateway_connection_dynamic}\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ“ Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyV2Agent\",\n",
    "    model_gateway_connection=model_gateway_connection_dynamic,\n",
    "    delete_before_create=True,\n",
    ")\n",
    "print(f\"   âœ… Agent created: {agent.name}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the history of Warsaw? Keep it brief.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"   ðŸ’¬ Conversation started: {conversation.id[:20]}...\")\n",
    "\n",
    "print(\"\\nâ³ Waiting for response...\")\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Response received!\")\n",
    "print(\"\\nðŸ’¬ Output:\")\n",
    "print(\"â”€\" * 40)\n",
    "print(response.output_text)\n",
    "print(\"â”€\" * 40)\n",
    "print(f\"\\nðŸ’° Usage: {response.to_dict()['usage']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŒŠ STREAMING RESPONSE TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing real-time streaming of agent responses\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ“ Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyAgentGpt5Mini\",\n",
    "    model_gateway_connection=model_gateway_connection_dynamic,\n",
    "    delete_before_create=True,\n",
    ")\n",
    "print(f\"   âœ… Agent: {agent.name}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me hi in 10 random languages.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"   ðŸ’¬ Conversation: {conversation.id[:20]}...\")\n",
    "\n",
    "# Create streaming response\n",
    "response_stream_events = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŒŠ Streaming response:\")\n",
    "print(\"â”€\" * 40)\n",
    "events_received = []\n",
    "\n",
    "async for event in response_stream_events:\n",
    "    previous_event = events_received[-1] if len(events_received) > 0 else None\n",
    "    if previous_event and previous_event[\"type\"] == event.type:\n",
    "        previous_event[\"count\"] += 1\n",
    "    else:\n",
    "        events_received.append({\"type\": event.type, \"count\": 1})\n",
    "\n",
    "    if event.type == \"response.created\":\n",
    "        print(f\"ðŸ†• Stream started (ID: {event.response.id})\\n\")\n",
    "    elif event.type == \"response.output_text.delta\":\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "    elif event.type == \"response.text.done\":\n",
    "        print(\"\\n\" + \"â”€\" * 40)\n",
    "        print(\"âœ… Text complete\")\n",
    "    elif event.type == \"response.completed\":\n",
    "        print(f\"\\nðŸŽ‰ Response completed!\")\n",
    "        print(f\"ðŸ’° Usage: {event.response.to_dict()['usage']}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Events received:\")\n",
    "for index, event in enumerate(events_received):\n",
    "    print(f\"   {index+1}. {event['type']} (Ã—{event['count']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents_utils import process_stream\n",
    "from openai import NOT_GIVEN\n",
    "\n",
    "print(\"ðŸ”§ STREAMING MCP TOOL CALLS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing MCP tool integration with streaming responses\")\n",
    "print()\n",
    "\n",
    "# Configure MCP tool\n",
    "mcp_tool = MCPTool(\n",
    "    server_label=\"ms-learn\",\n",
    "    server_url=\"https://learn.microsoft.com/api/mcp\",\n",
    "    require_approval=\"always\",\n",
    ")\n",
    "print(\"ðŸ”Œ MCP Tool configured:\")\n",
    "print(f\"   Label: {mcp_tool.server_label}\")\n",
    "print(f\"   URL: {mcp_tool.server_url}\")\n",
    "print(f\"   Approval: {mcp_tool.require_approval}\")\n",
    "\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "print(\"\\nðŸ“ Creating agent with tools...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyAgentGpt5MiniTools\",\n",
    "    model_gateway_connection=model_gateway_connection_static,\n",
    "    delete_before_create=True,\n",
    "    instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "    tools=tools,\n",
    ")\n",
    "print(f\"   âœ… Agent: {agent.name}\")\n",
    "print(f\"   ðŸ¤– Model: {agent.versions.latest.definition.model}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Find me learning paths on Microsoft Learn about Azure AI services.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"   ðŸ’¬ Conversation: {conversation.id[:20]}...\")\n",
    "\n",
    "# Streaming loop with tool approval\n",
    "events_received = []\n",
    "input_list = []\n",
    "response_id = None\n",
    "input = \"\"\n",
    "request_count = 0\n",
    "\n",
    "print(\"\\nðŸ”„ Starting tool call loop...\")\n",
    "print(\"â”€\" * 60)\n",
    "\n",
    "while True:\n",
    "    response_stream_events = await openai_client.responses.create(\n",
    "        conversation=conversation.id if response_id is None else NOT_GIVEN,\n",
    "        previous_response_id=response_id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "        input=input,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nðŸŒŠ Stream iteration #{request_count + 1}:\")\n",
    "    events_received, input_list, response_id, full_response = await process_stream(\n",
    "        response_stream_events\n",
    "    )\n",
    "\n",
    "    print(f\"\\nðŸ“Š Events in this iteration:\")\n",
    "    for index, event in enumerate(events_received):\n",
    "        print(f\"   {index+1}. {event['type']} (Ã—{event['count']})\")\n",
    "\n",
    "    if len(input_list) == 0:\n",
    "        break\n",
    "\n",
    "    input = input_list\n",
    "    print(f\"\\nâœ… Auto-approving {len(input_list)} tool request(s)...\")\n",
    "    request_count += 1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸŽ‰ Tool call loop completed!\")\n",
    "print(f\"   Total iterations: {request_count + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Streaming MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents_utils import process_response\n",
    "\n",
    "print(\"ðŸ”§ NON-STREAMING MCP TOOL CALLS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing MCP tools without streaming (synchronous)\")\n",
    "print()\n",
    "\n",
    "# Configure MCP tool\n",
    "mcp_tool = MCPTool(\n",
    "    server_label=\"docs\",\n",
    "    server_url=\"https://gitmcp.io/Azure/azure-rest-api-specs\",\n",
    "    require_approval=\"always\",\n",
    ")\n",
    "print(f\"ðŸ”Œ MCP Tool configured:\")\n",
    "print(f\"   Label: {mcp_tool.server_label}\")\n",
    "print(f\"   URL: {mcp_tool.server_url}\")\n",
    "\n",
    "# Load OpenAPI spec (optional - not used in this example)\n",
    "with open(\"weather.json\", \"r\") as f:\n",
    "    openapi_weather = jsonref.loads(f.read())\n",
    "    openapi_weather[\"servers\"] = [{\"url\": \"https://wttr.in\"}]\n",
    "print(f\"ðŸŒ¤ï¸ Weather OpenAPI spec loaded (available if needed)\")\n",
    "\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "print(\"\\nðŸ“ Creating agent with tools...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyAgentGpt5MiniTools\",\n",
    "    model_gateway_connection=model_gateway_connection_static,\n",
    "    delete_before_create=True,\n",
    "    instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "    tools=tools,\n",
    ")\n",
    "print(f\"   âœ… Agent: {agent.name}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "response_id = None\n",
    "input = \"\"\n",
    "input_list: ResponseInputParam = []\n",
    "request_count = 0\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\"type\": \"message\", \"role\": \"user\", \"content\": \"Summarize the readme from attached MCP tool for me. Keep it very brief.\"}\n",
    "    ],\n",
    ")\n",
    "print(f\"   ðŸ’¬ Conversation: {conversation.id[:20]}...\")\n",
    "\n",
    "print(\"\\nâ³ Sending initial request...\")\n",
    "while True:\n",
    "    response = await openai_client.responses.create(\n",
    "        conversation=conversation.id if response_id is None else NOT_GIVEN,\n",
    "        previous_response_id=response_id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "        input=input,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nðŸŒŠ Stream iteration #{request_count + 1}:\")\n",
    "    events_received, input_list, response_id, full_response = await process_response(\n",
    "        response\n",
    "    )\n",
    "\n",
    "    print(\"\\nðŸ“Š Events in this iteration:\")\n",
    "    for index, event in enumerate(events_received):\n",
    "        print(f\"   {index+1}. {event['type']} (Ã—{event['count']})\")\n",
    "\n",
    "    if len(input_list) == 0:\n",
    "        break\n",
    "\n",
    "    input = input_list\n",
    "    print(f\"\\nâœ… Auto-approving {len(input_list)} tool request(s)...\")\n",
    "    request_count += 1\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(response.output_text)\n",
    "print(\"\\nðŸ’° Full response details:\")\n",
    "print(f\"   Usage: {response.to_dict().get('usage', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Agent MCP Loop Tests\n",
    "Run multiple requests using an agent with MCP tools and capture:\n",
    "- âœ… Success/Error status for each iteration\n",
    "- ðŸ†” Request IDs for debugging\n",
    "- ðŸ“Š Summary statistics and success rate\n",
    "- ðŸ’¾ Results exported to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import APIStatusError, APIError, NOT_GIVEN\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from src.agents_utils import process_response\n",
    "\n",
    "\n",
    "print(\"ðŸ”§ MCP WITH AGENT - LOOP TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Running MCP tools with agent abstraction\")\n",
    "print(\"Testing with 10 iterations to capture errors and request IDs\")\n",
    "print()\n",
    "\n",
    "# Configure MCP tool\n",
    "mcp_tool = MCPTool(\n",
    "    server_label=\"weather\",\n",
    "    server_url=\"https://aca-mcp-qczp34j2qg7pk.ashyocean-7ea49412.westus.azurecontainerapps.io/mcp/mcp\",\n",
    "    require_approval=\"never\",\n",
    ")\n",
    "print(f\"ðŸ”Œ MCP Tool: {mcp_tool.server_label}\")\n",
    "print(f\"   URL: {mcp_tool.server_url}\")\n",
    "\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "# Create agent once at the top\n",
    "print(\"\\nðŸ“ Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MCPLoopTestAgent\",\n",
    "    # model_gateway_connection=model_gateway_connection_static,\n",
    "    deployment_name=\"gpt-5-mini\",\n",
    "    delete_before_create=True,\n",
    "    instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "    tools=tools,\n",
    ")\n",
    "print(f\"   âœ… Agent: {agent.name}\")\n",
    "print(f\"   ðŸ¤– Model: {agent.versions.latest.definition.model}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "\n",
    "# Configuration\n",
    "num_iterations = 10\n",
    "results = []\n",
    "\n",
    "print(f\"\\nâš™ï¸ Test Configuration:\")\n",
    "print(f\"   â€¢ Iterations: {num_iterations}\")\n",
    "print(f\"   â€¢ Agent: {agent.name}\")\n",
    "print()\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    print(f\"\\n{'â”€' * 60}\")\n",
    "    print(f\"ðŸ”„ Iteration {iteration + 1}/{num_iterations}\")\n",
    "    print(f\"{'â”€' * 60}\")\n",
    "    \n",
    "    request_id = None\n",
    "    result_status = None\n",
    "    error_msg = None\n",
    "    output_text = None\n",
    "    \n",
    "    try:\n",
    "        # Create new conversation for each iteration\n",
    "        random_number_a = iteration * 7 + 3\n",
    "        random_number_b = iteration * 11 + 5\n",
    "        conversation = await openai_client.conversations.create(\n",
    "            items=[\n",
    "                {\"type\": \"message\", \"role\": \"user\", \"content\": f\"Add {random_number_a} and {random_number_b} using MCP tool.\"}\n",
    "            ],\n",
    "        )\n",
    "        print(f\"   ðŸ’¬ Conversation: {conversation.id[:20]}...\")\n",
    "        response_id = None\n",
    "        input = \"\"\n",
    "        input_list: ResponseInputParam = []\n",
    "        request_count = 0\n",
    "\n",
    "        while True:\n",
    "            print(\"   â³ Sending request...\")\n",
    "            response = await openai_client.responses.create(\n",
    "                conversation=conversation.id if response_id is None else NOT_GIVEN,\n",
    "                previous_response_id=response_id,\n",
    "                extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "                input=input,\n",
    "            )\n",
    "\n",
    "            print(f\"\\nðŸŒŠ Request iteration #{request_count + 1}:\")\n",
    "            events_received, input_list, response_id, full_response = await process_response(\n",
    "                response\n",
    "            )\n",
    "\n",
    "            if len(input_list) == 0:\n",
    "                break\n",
    "\n",
    "            input = input_list\n",
    "            print(f\"\\nâœ… Auto-approving {len(input_list)} tool request(s)...\")\n",
    "            request_count += 1\n",
    "\n",
    "\n",
    "        request_id = response._request_id\n",
    "\n",
    "        result_status = \"SUCCESS\"\n",
    "        output_text = response.output_text[:100] if response.output_text else \"No output\"\n",
    "        print(f\"   âœ… SUCCESS\")\n",
    "        print(f\"      Request ID: {request_id}\")\n",
    "        print(f\"      Output: {output_text[:50]}...\")\n",
    "\n",
    "    except (APIStatusError, APIError, HttpResponseError) as e:\n",
    "        request_id = (\n",
    "            e.response.headers.get(\"x-request-id\", \"N/A\")\n",
    "            if hasattr(e, \"response\") and e.response is not None\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        result_status = \"ERROR\"\n",
    "        error_msg = str(e)\n",
    "        print(f\"   âŒ ERROR\")\n",
    "        print(f\"      Request ID: {request_id}\")\n",
    "        print(f\"      Error: {error_msg}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        result_status = \"ERROR\"\n",
    "        error_msg = str(e)\n",
    "        print(f\"   âŒ ERROR\")\n",
    "        print(f\"      Request ID: N/A\")\n",
    "        print(f\"      Error: {error_msg}\")\n",
    "\n",
    "    # Record results\n",
    "    results.append({\n",
    "        \"Iteration\": iteration + 1,\n",
    "        \"Request ID\": request_id or \"N/A\",\n",
    "        \"Result\": result_status,\n",
    "        \"Output/Error\": output_text if result_status == \"SUCCESS\" else error_msg,\n",
    "    })\n",
    "\n",
    "# Create DataFrame and display results\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“Š RESULTS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "csv_file = \"mcp_agent_test_results.csv\"\n",
    "df_results.to_csv(csv_file, index=False)\n",
    "print(f\"\\nðŸ’¾ Results saved to: {csv_file}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“ˆ SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "total = len(results)\n",
    "successes = len([r for r in results if r[\"Result\"] == \"SUCCESS\"])\n",
    "errors = len([r for r in results if r[\"Result\"] == \"ERROR\"])\n",
    "success_rate = (successes / total * 100) if total > 0 else 0\n",
    "\n",
    "print(f\"   âœ… Successes: {successes}\")\n",
    "print(f\"   âŒ Errors: {errors}\")\n",
    "print(f\"   ðŸŽ¯ Success Rate: {success_rate:.1f}%\")\n",
    "\n",
    "if success_rate == 100:\n",
    "    print(\"\\nðŸŽ‰ All tests passed!\")\n",
    "elif success_rate >= 50:\n",
    "    print(\"\\nâš ï¸ Some tests failed - check the results above\")\n",
    "else:\n",
    "    print(\"\\nâŒ Most tests failed - investigate connection issues\")\n",
    "\n",
    "# Display unique request IDs for debugging\n",
    "print(\"\\nðŸ“‹ Request IDs:\")\n",
    "for r in results:\n",
    "    status_icon = \"âœ…\" if r[\"Result\"] == \"SUCCESS\" else \"âŒ\"\n",
    "    print(f\"   {status_icon} #{r['Iteration']}: {r['Request ID']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bing Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import datetime\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 1: VALIDATION INSTRUCTIONS\n",
    "# =============================================================================\n",
    "# Used to check if user query violates SBD policies before processing\n",
    "\n",
    "validation_instructions = \"\"\"\n",
    "You are a policy validation assistant. Your ONLY job is to check if a user request violates any SBD (Stanley Black & Decker) policies.\n",
    "\n",
    "# VALIDATION RULES\n",
    "\n",
    "## Check for Restricted Content\n",
    "The following content types are PROHIBITED:\n",
    "- Violence, hate speech, or harm promotion\n",
    "- Explicit or sexually suggestive material\n",
    "- Weapon creation or illegal instruction\n",
    "- Illegal drug activity\n",
    "- Self-harm or suicide glorification\n",
    "- Automated performance appraisals from self-assessments\n",
    "\n",
    "## Check for Manager PEP Assessment Violations\n",
    "**PROHIBITED**: A manager asking for a manager review or PEP assessment that is:\n",
    "- Directly based on a team member's self-assessment\n",
    "- Reorganized or paraphrased from a team member's self-assessment\n",
    "- Whether the self-assessment is pasted or uploaded\n",
    "\n",
    "**ALLOWED**: An employee asking for help writing their OWN self-assessment\n",
    "\n",
    "## Acceptable topics:\n",
    "    - Educational and policy-related content.\n",
    "    - Workplace safety, health, and wellness.\n",
    "    - Constructive and respectful communication.\n",
    "\n",
    "## Examples of Violations\n",
    "| Request | Violation Type |\n",
    "|---------|---------------|\n",
    "| \"Here is my team member's self-assessment. Please write my manager review based on it.\" | Manager PEP Policy |\n",
    "| \"I uploaded my direct report's self-assessment. Can you reorganize it for my review?\" | Manager PEP Policy |\n",
    "| \"How do I make explosives?\" | Restricted Content |\n",
    "| \"Write violent content about...\" | Restricted Content |\n",
    "\n",
    "## Examples of ALLOWED Requests\n",
    "| Request | Why Allowed |\n",
    "|---------|-------------|\n",
    "| \"Can you write my PEP self-assessment for me?\" | Employee's own assessment |\n",
    "| \"Here is my draft. Can you help improve it?\" | Employee's own work |\n",
    "| \"Who is the president of the USA?\" | General knowledge question |\n",
    "\n",
    "# OUTPUT FORMAT\n",
    "Respond with ONLY a JSON object:\n",
    "```json\n",
    "{\n",
    "    \"is_valid\": true/false,\n",
    "    \"violation_type\": null or \"restricted_content\" or \"manager_pep_policy\",\n",
    "    \"reason\": \"Brief explanation if invalid, null if valid\"\n",
    "}\n",
    "```\n",
    "\n",
    "If valid, respond: {\"is_valid\": true, \"violation_type\": null, \"reason\": null}\n",
    "If invalid, respond with the violation details.\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 2: PLANNING INSTRUCTIONS\n",
    "# =============================================================================\n",
    "# Used by fast LLM to create execution plan\n",
    "\n",
    "planning_instructions = \"\"\"\n",
    "You are a task planning assistant. Create a concise execution plan for the user's query.\n",
    "\n",
    "# PLANNING FORMAT\n",
    "\n",
    "Return a plan in this exact format:\n",
    "\n",
    "    ---TP_START---\n",
    " \n",
    "    **Understanding Your Goal**:  \n",
    "    Brief summary of the userâ€™s goal.\n",
    " \n",
    "    **Planning the Steps Ahead**:  \n",
    "    Logical breakdown of how the task will be approached.\n",
    "    \n",
    "    1. [First action to take]\n",
    "    2. [Second action if needed]\n",
    "    3. [Continue as needed]\n",
    " \n",
    "    **Selecting the Right Tools**  \n",
    "        Specify any tools needed for this task. Choose from the following:\n",
    "        - `bing_grounding`: YES/NO - [reason if YES]: For retrieving real-time or web-based information.  \n",
    "        - `code_interpreter`: YES/NO - [reason if YES]: For executing code, performing data analysis, or generating visualizations.  \n",
    " \n",
    "    **Defining What You'll Receive**  \n",
    "        Clearly outline the expected final outcome of the taskâ€”whether it's a summary, recommendation, chart, analysis, explanation, or code snippet.\n",
    " \n",
    "    ---TP_END---\n",
    "\n",
    "# TOOL SELECTION GUIDELINES\n",
    "\n",
    "Use `bing_grounding` when:\n",
    "- Question asks about current events, news, or recent happenings\n",
    "- Question asks about current prices, rates, or market data\n",
    "- Question asks about weather or forecasts\n",
    "- Question asks \"who is the current...\" or \"what is the latest...\"\n",
    "- Information may have changed since your training data\n",
    "- User explicitly asks for web search or current info\n",
    "\n",
    "Do NOT use `bing_grounding` when:\n",
    "- Question is about general knowledge that doesn't change\n",
    "- Question is about historical facts\n",
    "- Question is about math, coding, or logic problems\n",
    "- You can confidently answer from training data\n",
    "\n",
    "# IMPORTANT\n",
    "- Keep the plan concise (under 200 words)\n",
    "- Be explicit about which tools are needed\n",
    "- If `bing_grounding` is needed, say YES with the search intent\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 3: EXECUTION INSTRUCTIONS\n",
    "# =============================================================================\n",
    "# Used by the agent to execute the plan and respond to user\n",
    "\n",
    "execution_instructions = \"\"\"\n",
    "You are CHATSBDPLUS, an enterprise-grade AI assistant. Execute the provided plan and respond to the user.\n",
    "\n",
    "# EXECUTION RULES\n",
    "\n",
    "## Tool Usage\n",
    "- You MUUST execute tool calls as specified in the plan\n",
    "- Do NOT mention the search process or queries to the user\n",
    "- Do NOT explain that you're using tools - just use them and provide results\n",
    "- If a tool fails, try an alternative approach or explain the limitation\n",
    "\n",
    "## Response Formatting\n",
    "Use proper Markdown:\n",
    "- Headings (#, ##, ###) for structure\n",
    "- Bullet and numbered lists for clarity\n",
    "- Code blocks (```language) for code\n",
    "- Tables when presenting comparative data\n",
    "- **Bold** for emphasis, _italic_ for terms\n",
    "\n",
    "## Citation Rules\n",
    "- Use **inline citations** immediately after facts they support\n",
    "- Do NOT use end-of-response citation sections\n",
    "- For tables, include citation as caption above/below\n",
    "\n",
    "## Quality Standards\n",
    "- Provide clear, structured answers\n",
    "- Maintain professional tone\n",
    "- Be concise but complete\n",
    "- If uncertain about fast-changing info, state:\n",
    "  \"This is the most current information available. Please verify with official sources for the latest updates.\"\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "# REFLECTION & SELF-REVISION (FOR COMPLEX TASKS)\n",
    " \n",
    "- **When to Use**:\n",
    "    Apply a reflection process after completing the initial plan or response, especially for:\n",
    "    - Complex, multi-step reasoning\n",
    "    - Safety-critical topics\n",
    "    - Sensitive or policy-restricted tasks\n",
    " \n",
    "- **How to Reflect**:\n",
    "    After drafting your response, internally run this reflection prompt:\n",
    " \n",
    "    **Reflection Prompt**:  \n",
    "    *â€œIs there anything I missed, misunderstood, or could improve in this response? Is the reasoning clear, complete, and policy-compliant?â€*\n",
    " \n",
    "    If the reflection identifies any gaps, update the output before sharing with the user.\n",
    " \n",
    "- **Execution Notes**:\n",
    "    - This reflection should be applied **internally** and not shown to the user unless explicitly requested.\n",
    "    - Always prioritize factual accuracy, safety alignment, and structured clarity.\n",
    " \n",
    "--------------------------------------------------------------------------------\n",
    "# TRANSPARENCY & LIMITATIONS\n",
    " \n",
    "When uncertain or referencing fast-changing information, state:\n",
    " \n",
    "**\"This is the most current information available at the time of response. Please verify with official sources for the latest updates.\"**\n",
    "  \n",
    "# IMPORTANT\n",
    "- Execute the plan, don't re-plan\n",
    "- Respond directly to the user's question\n",
    "- Do not include the plan in your response\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# COMBINED INSTRUCTIONS (for agents that need all phases)\n",
    "# =============================================================================\n",
    "\n",
    "docless_agent_instructions = \"\"\"\n",
    "You are CHATSBDPLUS, an enterprise-grade AI assistant designed to assist employees with accurate, safe, and structured responses. You do not rely on uploaded document content but can retrieve real-time information through a secure Bing-based grounding engine.\n",
    "--------------------------------------------------------------------------------\n",
    "# ROLE & SCOPE\n",
    " \n",
    "You are expected to:\n",
    " \n",
    "    - Provide **clear, structured answers** to employee questions.\n",
    "    - Retrieve **real-time information** using Bing grounding when needed.\n",
    "    - Handle supported file formats: **.pdf, .pptx, .docx, .txt, .jpeg, .jpg, .png, .csv, .json, .xlsx** (up to 512MB).\n",
    "    - Maintain **professional tone** and context continuity across interactions.\n",
    " \n",
    "--------------------------------------------------------------------------------\n",
    "# SAFETY RULES\n",
    " \n",
    "Always comply with SBD safety standards. If a user prompt violates policy, respond with:\n",
    " \n",
    "**`This prompt cannot be processed as it is restricted by SBD policy.`**\n",
    " \n",
    "## Restricted content includes:\n",
    "    - Violence, hate speech, or harm promotion.\n",
    "    - Explicit or sexually suggestive material.\n",
    "    - Weapon creation or illegal instruction.\n",
    "    - Illegal drug activity.\n",
    "    - Self-harm or suicide glorification.\n",
    "    - Automated performance appraisals from self-assessments.\n",
    " \n",
    "## Acceptable topics:\n",
    "    - Educational and policy-related content.\n",
    "    - Workplace safety, health, and wellness.\n",
    "    - Constructive and respectful communication.\n",
    "\n",
    "# Agent Instructions: Enforcing SBD Policy on Manager PEP Assessment Requests\n",
    "\n",
    "## **Policy Overview**\n",
    "Agents must **not** generate a manager review or PEP assessment that is directly based on, reorganized, or paraphrased from a team member's self-assessment (whether pasted or uploaded by the manager).  \n",
    "Requests from employees to help write their own self-assessment, even without an initial draft, are permitted.\n",
    "\n",
    "## **Required Response for Non-Compliant Manager Requests**\n",
    "If a manager asks for a manager review to be written directly from a team memberâ€™s self-assessment (by pasting or uploading it), you are required to respond with the following message:\n",
    "\n",
    "> **This request is outside of Stanley Black & Decker Policy.**\n",
    "\n",
    "## **Step-by-Step Instructions**\n",
    "\n",
    "1. **Check the User Request:**\n",
    "   - If a manager provides a team memberâ€™s self-assessment (pasted or uploaded) and asks for a manager review to be written directly from it, treat this as non-compliant and proceed to Step 2.\n",
    "   - If an employee requests help writing their own self-assessment, proceed with assistance.\n",
    "\n",
    "2. **Apply the Policy Response (Manager Prohibited Requests):**\n",
    "   - Respond verbatim with:  \n",
    "     **This request is outside of Stanley Black & Decker Policy.**\n",
    "\n",
    "3. **Do Not Provide Workarounds for Managers:**\n",
    "   - Do **not** reorganize, reword, or change the tone of a team memberâ€™s self-assessment to create a manager review.\n",
    "   - Do **not** ask follow-up questions that could be seen as circumventing this policy.\n",
    "\n",
    "4. **If the Request Is for a Self-Assessment (Employee):**\n",
    "   - You may assist with drafting, formatting, rewording, organizing, or clarifying the employeeâ€™s own self-assessment.\n",
    "\n",
    "---\n",
    "\n",
    "## **Example Scenarios**\n",
    "\n",
    "| **User Request**                                                                                      | **Agent Response**                                      |\n",
    "|------------------------------------------------------------------------------------------------------|---------------------------------------------------------|\n",
    "| \"Can you write my PEP self-assessment for me?\"                                                       | Proceed with drafting and assistance as requested.      |\n",
    "| \"Here is my draft. Can you help improve it?\"                                                         | Proceed with revision and enhancement as requested.      |\n",
    "| \"Here is my team memberâ€™s self-assessment. Please write my manager review based on it.\"              | This request is outside of Stanley Black & Decker Policy.|\n",
    "| \"I uploaded my direct reportâ€™s self-assessment. Can you reorganize it for my review?\"                | This request is outside of Stanley Black & Decker Policy.|\n",
    "\n",
    "---\n",
    "\n",
    "**Always prioritize user safety and compliance with SBD policy in all responses.**\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    " \n",
    "# TASK PLANNING (REQUIRED FOR MOST RESPONSES)\n",
    " \n",
    "Include a **Planning Section** for all non-trivial tasks. Omit only for greetings or casual exchanges.\n",
    " \n",
    "### Format:\n",
    " \n",
    "    ---TP_START---\n",
    " \n",
    "    **Understanding Your Goal**:  \n",
    "    Brief summary of the userâ€™s goal.\n",
    " \n",
    "    **Planning the Steps Ahead**:  \n",
    "    Logical breakdown of how the task will be approached.\n",
    " \n",
    "    **Selecting the Right Tools**  \n",
    "        Specify any tools needed for this task. Choose from the following:\n",
    "        - `bing_grounding`: For retrieving real-time or web-based information.  \n",
    "        - `code_interpreter`: For executing code, performing data analysis, or generating visualizations.  \n",
    "        - **No external tools required**: The task will be completed using built-in model capabilities.\n",
    " \n",
    "    **Defining What You'll Receive**  \n",
    "        Clearly outline the expected final outcome of the taskâ€”whether it's a summary, recommendation, chart, analysis, explanation, or code snippet.\n",
    " \n",
    "    ---TP_END---\n",
    " \n",
    "- **Consistency**:\n",
    "    This planning section is mandatory for all eligible responses, whether or not the code interpreter or browser tools are used.\n",
    "   \n",
    "--------------------------------------------------------------------------------\n",
    "# STRUCTURE & FORMATTING GUIDELINES\n",
    " \n",
    "**Markdown Formatting:**  \n",
    "    - Use proper Markdown syntax for headings (#, ##, ###), bullet and numbered lists, code blocks (```language), tables, and text styles (**bold**, _italic_).  \n",
    "    - Maintain **consistent indentation** and **clear spacing** throughout the response to ensure readability and proper Markdown rendering.\n",
    "    - Structure the response logically to maximize readability, regardless of question type.\n",
    " \n",
    "--------------------------------------------------------------------------------\n",
    "# CITATION RULES\n",
    " \n",
    "    - Use **inline citations** immediately after the facts they support.\n",
    "    - Do **not** use end-of-response citation sections (e.g., \"References\").\n",
    "    - For tables, include citation as a caption above/below the table.\n",
    " \n",
    "--------------------------------------------------------------------------------\n",
    "# REAL-TIME INFORMATION (BING GROUNDING ENGINE)\n",
    " \n",
    "**Use `bing_grounding` tool only** for dynamic information needs such as:\n",
    "    - Current events, weather, date, policies, company news, or market trends.\n",
    "    - When user requests web search or info may be outdated.\n",
    "    - **Do NOT mention** the search process or query.\n",
    "    - Respond with only the relevant factual content using clear and professional language.\n",
    " \n",
    "### Instructions:\n",
    "    - Retrieve only relevant, verified content.\n",
    "    - Cite sources inline.\n",
    "    - Do not list citations only at the end.\n",
    " \n",
    "--------------------------------------------------------------------------------\n",
    "# REFLECTION & SELF-REVISION (FOR COMPLEX TASKS)\n",
    " \n",
    "- **When to Use**:\n",
    "    Apply a reflection process after completing the initial plan or response, especially for:\n",
    "    - Complex, multi-step reasoning\n",
    "    - Safety-critical topics\n",
    "    - Sensitive or policy-restricted tasks\n",
    " \n",
    "- **How to Reflect**:\n",
    "    After drafting your response, internally run this reflection prompt:\n",
    " \n",
    "    **Reflection Prompt**:  \n",
    "    *â€œIs there anything I missed, misunderstood, or could improve in this response? Is the reasoning clear, complete, and policy-compliant?â€*\n",
    " \n",
    "    If the reflection identifies any gaps, update the output before sharing with the user.\n",
    " \n",
    "- **Execution Notes**:\n",
    "    - This reflection should be applied **internally** and not shown to the user unless explicitly requested.\n",
    "    - Always prioritize factual accuracy, safety alignment, and structured clarity.\n",
    " \n",
    "--------------------------------------------------------------------------------\n",
    "# TRANSPARENCY & LIMITATIONS\n",
    " \n",
    "When uncertain or referencing fast-changing information, state:\n",
    " \n",
    "**\"This is the most current information available at the time of response. Please verify with official sources for the latest updates.\"**\n",
    "\"\"\"\n",
    " \n",
    "async def validate_query(query: str, openai_client) -> dict:\n",
    "    \"\"\"Validate user query against SBD policies.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question to validate\n",
    "        openai_client: The OpenAI client instance\n",
    "        \n",
    "    Returns:\n",
    "        Dict with is_valid, violation_type, and reason\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    try:\n",
    "        response = await asyncio.wait_for(\n",
    "            openai_client.responses.create(\n",
    "                model=\"gpt-oss-120b\",\n",
    "                input=f\"Validate this user request:\\n\\n{query}\",\n",
    "                instructions=validation_instructions,\n",
    "                max_output_tokens=200,\n",
    "            ),\n",
    "            timeout=10.0,\n",
    "        )\n",
    "        \n",
    "        result_text = response.output_text.strip()\n",
    "        # Extract JSON from response\n",
    "        if \"```json\" in result_text:\n",
    "            result_text = result_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in result_text:\n",
    "            result_text = result_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "            \n",
    "        result = json.loads(result_text)\n",
    "        print(f\"   âœ… Validation: {'PASSED' if result.get('is_valid') else 'FAILED'}\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Validation error: {e}, allowing query\")\n",
    "        return {\"is_valid\": True, \"violation_type\": None, \"reason\": None}\n",
    "\n",
    "\n",
    "async def get_plan(query: str, openai_client) -> str:\n",
    "    \"\"\"Generate a task plan using a fast LLM.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question to plan for\n",
    "        openai_client: The OpenAI client instance\n",
    "        \n",
    "    Returns:\n",
    "        The generated plan text, or a fallback plan on error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = await asyncio.wait_for(\n",
    "            openai_client.responses.create(\n",
    "                model=\"gpt-oss-120b\",\n",
    "                input=f\"Today is {datetime.datetime.now(datetime.timezone.utc)}. Create an execution plan for:\\n\\n'{query}'\",\n",
    "                instructions=planning_instructions,\n",
    "                max_output_tokens=500,\n",
    "            ),\n",
    "            timeout=30.0,\n",
    "        )\n",
    "        \n",
    "        plan = response.output_text\n",
    "        if not plan or len(plan.strip()) == 0:\n",
    "            print(\"   âš ï¸ Planner returned empty response, using fallback\")\n",
    "            return f\"Search for: {query}\"\n",
    "            \n",
    "        print(f\"   ðŸ§  Plan generated ({len(plan.split())} words)\")\n",
    "        return plan\n",
    "        \n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"   âš ï¸ Planner timed out, using fallback\")\n",
    "        return f\"Search for: {query}\"\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"   âš ï¸ Planner connection error: {e}\")\n",
    "        return f\"Search for: {query}\"\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"   âš ï¸ Planner rate limited: {e}\")\n",
    "        return f\"Search for: {query}\"\n",
    "    except openai.APIStatusError as e:\n",
    "        print(f\"   âš ï¸ Planner API error ({e.status_code}): {e.message}\")\n",
    "        return f\"Search for: {query}\"\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Planner unexpected error: {type(e).__name__}: {e}\")\n",
    "        return f\"Search for: {query}\"\n",
    "\n",
    "\n",
    "# Test the functions\n",
    "print(\"ðŸ“‹ INSTRUCTION SETS DEFINED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   1ï¸âƒ£  validation_instructions: {len(validation_instructions)} chars\")\n",
    "print(f\"   2ï¸âƒ£  planning_instructions: {len(planning_instructions)} chars\")\n",
    "print(f\"   3ï¸âƒ£  execution_instructions: {len(execution_instructions)} chars\")\n",
    "print(f\"   ðŸ“¦ docless_agent_instructions (combined): {len(docless_agent_instructions)} chars\")\n",
    "print()\n",
    "print(\"ðŸ”§ Functions available:\")\n",
    "print(\"   â€¢ validate_query(query, client) â†’ {is_valid, violation_type, reason}\")\n",
    "print(\"   â€¢ get_plan(query, client) â†’ plan string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import (\n",
    "    BingGroundingAgentTool,\n",
    "    BingGroundingSearchConfiguration,\n",
    "    BingGroundingSearchToolParameters,\n",
    "    CodeInterpreterTool,\n",
    ")\n",
    "from src.foundry_utils import get_bing_grounding_connection\n",
    "from src.agents_utils import process_response\n",
    "\n",
    "bing_connection_id = await get_bing_grounding_connection(agents_client.client)\n",
    "if not bing_connection_id:\n",
    "    raise Exception(\"Bing Grounding connection not found. Please create one in the AI Foundry project.\")\n",
    "\n",
    "bing_configuration = BingGroundingSearchConfiguration(\n",
    "    project_connection_id=bing_connection_id,\n",
    "    count=10\n",
    ")\n",
    "bing_parameters = BingGroundingSearchToolParameters(\n",
    "    search_configurations=[bing_configuration],\n",
    ")\n",
    "bing_tool = BingGroundingAgentTool(bing_grounding=bing_parameters)\n",
    "code_interpreter_tool = CodeInterpreterTool()\n",
    "tools: list[Tool] = [bing_tool, code_interpreter_tool]\n",
    "\n",
    "openai_client = agents_client.client.get_openai_client()\n",
    "\n",
    "# Create agent once at the top\n",
    "print(\"\\nðŸ“ Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"BingGroundingAgent\",\n",
    "    # model_gateway_connection=ai_gateway_connection_static,\n",
    "    deployment_name=\"gpt-5-mini\",\n",
    "    delete_before_create=False,\n",
    "    instructions=execution_instructions,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\"type\": \"message\", \"role\": \"assistant\", \"content\": f\"Today is {datetime.datetime.now(datetime.timezone.utc)}. Use Bing search to find current information.\"},\n",
    "        {\"type\": \"message\", \"role\": \"user\", \"content\": \"Who is the president of USA?\"}\n",
    "    ],\n",
    ")\n",
    "input = \"\"\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    previous_response_id=None,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    parallel_tool_calls=True,\n",
    "    tool_choice=\"required\",  # Forces the model to use a tool\n",
    "    input=input,\n",
    ")\n",
    "\n",
    "events_received, input_list, response_id, full_response = await process_response(\n",
    "    response\n",
    ")\n",
    "print(\"\\nâœ… Response received!\")\n",
    "print(f\"   ðŸ†” Response ID: {response.id}\")\n",
    "print(\"\\n Events:\")\n",
    "for event in events_received:\n",
    "    print(f\"   - {event}\")\n",
    "print(\"\\nðŸ’¬ Final Response:\")\n",
    "print(full_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bing Grounding Evaluation Loop\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from openai.types.responses import ToolChoiceAllowedParam\n",
    "\n",
    "print(\"ðŸ” BING GROUNDING EVALUATION LOOP\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Running 10 iterations with random current-events questions\")\n",
    "print(\"Verifying Bing search is triggered and returns relevant info\")\n",
    "print()\n",
    "\n",
    "# Questions that should trigger Bing grounding (current events, recent info)\n",
    "grounding_questions = [\n",
    "    {\"question\": \"Who is the current president of the United States?\", \"expected_keywords\": [\"donald\", \"trump\"]},\n",
    "    {\"question\": \"What is the current price of Bitcoin today?\", \"expected_keywords\": [\"bitcoin\", \"$\"]},\n",
    "    {\"question\": \"What are the latest news headlines today?\", \"expected_keywords\": [\"news\", \"today\"]},\n",
    "    {\"question\": \"What is the weather forecast for New York City?\", \"expected_keywords\": [\"weather\", \"new york\"]},\n",
    "    {\"question\": \"Who won the most recent Super Bowl?\", \"expected_keywords\": [\"super bowl\", \"win\"]},\n",
    "    {\"question\": \"What are the current stock market indices?\", \"expected_keywords\": [\"stock\", \"market\"]},\n",
    "    {\"question\": \"What is the latest score in the NBA playoffs?\", \"expected_keywords\": [\"nba\", \"score\"]},\n",
    "    {\"question\": \"What movies are currently playing in theaters?\", \"expected_keywords\": [\"movie\", \"theater\"]},\n",
    "    {\"question\": \"What is the current exchange rate for USD to EUR?\", \"expected_keywords\": [\"usd\", \"eur\", \"exchange\"]},\n",
    "    {\"question\": \"What are the trending topics on social media right now?\", \"expected_keywords\": [\"trend\", \"social\"]},\n",
    "    {\"question\": \"Who is the current CEO of OpenAI?\", \"expected_keywords\": [\"openai\", \"ceo\"]},\n",
    "    {\"question\": \"What is the latest iPhone model released by Apple?\", \"expected_keywords\": [\"iphone\", \"apple\"]},\n",
    "    {\"question\": \"What are the current gas prices in the US?\", \"expected_keywords\": [\"gas\", \"price\"]},\n",
    "    {\"question\": \"Who is the Prime Minister of the United Kingdom?\", \"expected_keywords\": [\"prime minister\", \"uk\"]},\n",
    "    {\"question\": \"What major events happened in the world this week?\", \"expected_keywords\": [\"event\", \"week\"]},\n",
    "]\n",
    "\n",
    "num_iterations = 10\n",
    "results = []\n",
    "\n",
    "# Randomly select questions for each iteration\n",
    "selected_questions = random.sample(grounding_questions, min(num_iterations, len(grounding_questions)))\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    print(f\"\\n{'â”€' * 50}\")\n",
    "    print(f\"ðŸ”„ Iteration {i + 1}/{num_iterations}\")\n",
    "    \n",
    "    # Start timing\n",
    "    iteration_start = time.perf_counter()\n",
    "    \n",
    "    # Get question for this iteration (cycle if needed)\n",
    "    q = selected_questions[i % len(selected_questions)]\n",
    "    question = q[\"question\"]\n",
    "    expected_keywords = q[\"expected_keywords\"]\n",
    "    \n",
    "    print(f\"   â“ Question: {question}\")\n",
    "    print(f\"   ðŸ” Expected keywords: {expected_keywords}\")\n",
    "    \n",
    "    try:\n",
    "        # create a plan\n",
    "        plan_task = get_plan(question, openai_client)\n",
    "        validation_task = validate_query(question, openai_client)\n",
    "\n",
    "        # run in parallel - use different variable name to avoid overwriting results list\n",
    "        parallel_results = await asyncio.gather(plan_task, validation_task)\n",
    "        plan, validation = parallel_results\n",
    "\n",
    "        print(\"   ðŸ” Plan:\")\n",
    "        print(\"------------\")\n",
    "        print(plan)\n",
    "        print(\"------------\")\n",
    "\n",
    "        if not validation.get(\"is_valid\", True):\n",
    "            elapsed_time = time.perf_counter() - iteration_start\n",
    "            print(f\"   âŒ Query invalid due to policy violation: {validation.get('violation_type')} - {validation.get('reason')}\")\n",
    "            print(f\"   â±ï¸ Time: {elapsed_time:.2f}s\")\n",
    "            results.append({\n",
    "                \"Iteration\": i + 1,\n",
    "                \"Question\": question[:250] + \"...\",\n",
    "                \"Bing Called\": False,\n",
    "                \"Keywords Found\": \"N/A\",\n",
    "                \"Plan Contains Bing\": False,\n",
    "                \"Passed\": False,\n",
    "                \"Events\": \"N/A\",\n",
    "                \"Response\": f\"Query invalid: {validation.get('violation_type')}\",\n",
    "                \"Request ID\": \"N/A\",\n",
    "                \"Time (s)\": round(elapsed_time, 2)\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Check if plan requires bing_grounding\n",
    "        plan_requires_bing = \"`bing_grounding`: yes\" in plan.lower()\n",
    "        \n",
    "        # Determine tool_choice based on plan using ToolChoiceAllowedParam format\n",
    "        # See: openai/types/responses/tool_choice_allowed_param.py\n",
    "        if plan_requires_bing:\n",
    "            tool_choice_setting = \"required\"\n",
    "            print(f\"   ðŸŽ¯ Plan requires Bing â†’ forcing tool_choice with allowed_tools (bing_grounding only)\")\n",
    "        else:\n",
    "            tool_choice_setting = \"auto\"\n",
    "            print(f\"   â„¹ï¸ Plan doesn't require Bing â†’ tool_choice=auto\")\n",
    "\n",
    "        # Create fresh conversation each time\n",
    "        conversation = await openai_client.conversations.create(\n",
    "            items=[\n",
    "                {\"type\": \"message\", \"role\": \"assistant\", \"content\": f\"Today is {datetime.datetime.now(datetime.timezone.utc)}.\"},\n",
    "                {\"type\": \"message\", \"role\": \"user\", \"content\": f\"Plan: {plan}\\n\\n User Question: {question}\"},\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        response = await openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            previous_response_id=None,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            parallel_tool_calls=True,\n",
    "            tool_choice=tool_choice_setting,\n",
    "            input=\"\",\n",
    "        )\n",
    "        \n",
    "        events_received, input_list, response_id, full_response = await process_response(response)\n",
    "        \n",
    "        # Stop timing\n",
    "        elapsed_time = time.perf_counter() - iteration_start\n",
    "        \n",
    "        # Check if Bing grounding was actually called\n",
    "        event_types = [e[\"type\"] for e in events_received]\n",
    "        bing_called = any(\"bing_grounding\" in t.lower() for t in event_types)\n",
    "        \n",
    "        # Check for expected keywords (case-insensitive)\n",
    "        response_text = full_response.lower() if full_response else \"\"\n",
    "        keywords_found = [kw for kw in expected_keywords if kw.lower() in response_text]\n",
    "        keywords_passed = len(keywords_found) > 0\n",
    "        plan_passed = \"bing_grounding\" in plan.lower()\n",
    "        \n",
    "        # Both conditions must pass\n",
    "        passed = bing_called and keywords_passed and plan_passed\n",
    "        \n",
    "        bing_status = \"âœ…\" if bing_called else \"âŒ\"\n",
    "        keywords_status = \"âœ…\" if keywords_passed else \"âŒ\"\n",
    "        plan_status = \"âœ…\" if plan_passed else \"âŒ\"\n",
    "        overall_status = \"âœ… PASS\" if passed else \"âŒ FAIL\"\n",
    "        \n",
    "        print(f\"   {overall_status}\")\n",
    "        print(f\"   ðŸ”§ Bing grounding called: {bing_status} ({', '.join(event_types)})\")\n",
    "        print(f\"   ðŸ“ Keywords found: {keywords_status} ({keywords_found if keywords_found else 'None'})\")\n",
    "        print(f\"   ðŸ“‹ Plan contains Bing grounding: {plan_status}\")\n",
    "        print(f\"   â±ï¸ Time: {elapsed_time:.2f}s\")\n",
    "        print(f\"   Response: {full_response[:200] if full_response else 'No response'}...\")\n",
    "        \n",
    "        results.append({\n",
    "            \"Iteration\": i + 1,\n",
    "            \"Question\": question[:250] + \"...\",\n",
    "            \"Bing Called\": bing_called,\n",
    "            \"Keywords Found\": \", \".join(keywords_found) if keywords_found else \"None\",\n",
    "            \"Plan Contains Bing\": plan_passed,\n",
    "            \"Passed\": passed,\n",
    "            \"Events\": \", \".join(event_types),\n",
    "            \"Response\": full_response if full_response else \"No response\",\n",
    "            \"Request ID\": response._request_id or \"N/A\",\n",
    "            \"Time (s)\": round(elapsed_time, 2)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed_time = time.perf_counter() - iteration_start\n",
    "        print(f\"   âŒ ERROR: {str(e)}\")\n",
    "        print(f\"   â±ï¸ Time: {elapsed_time:.2f}s\")\n",
    "        results.append({\n",
    "            \"Iteration\": i + 1,\n",
    "            \"Question\": question[:250] + \"...\",\n",
    "            \"Bing Called\": False,\n",
    "            \"Keywords Found\": \"ERROR\",\n",
    "            \"Plan Contains Bing\": \"ERROR\",\n",
    "            \"Passed\": False,\n",
    "            \"Events\": \"ERROR\",\n",
    "            \"Response\": f\"ERROR: {str(e)}\",\n",
    "            \"Request ID\": \"N/A\",\n",
    "            \"Time (s)\": round(elapsed_time, 2)\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“Š EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df[[\"Iteration\", \"Question\", \"Bing Called\", \"Keywords Found\", \"Plan Contains Bing\", \"Passed\", \"Time (s)\"]].to_string(index=False))\n",
    "\n",
    "total = len(results)\n",
    "passed_count = len([r for r in results if r[\"Passed\"]])\n",
    "bing_called_count = len([r for r in results if r[\"Bing Called\"]])\n",
    "plan_contains_bing_count = len([r for r in results if r.get(\"Plan Contains Bing\") == True])\n",
    "pass_rate = (passed_count / total * 100) if total > 0 else 0\n",
    "bing_rate = (bing_called_count / total * 100) if total > 0 else 0\n",
    "plan_rate = (plan_contains_bing_count / total * 100) if total > 0 else 0\n",
    "\n",
    "# Timing statistics\n",
    "times = [r[\"Time (s)\"] for r in results]\n",
    "avg_time = sum(times) / len(times) if times else 0\n",
    "min_time = min(times) if times else 0\n",
    "max_time = max(times) if times else 0\n",
    "total_time = sum(times)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Overall Pass Rate: {passed_count}/{total} ({pass_rate:.1f}%)\")\n",
    "print(f\"ðŸ”§ Bing Grounding Called: {bing_called_count}/{total} ({bing_rate:.1f}%)\")\n",
    "print(f\"ðŸ“‹ Plan Contains Bing: {plan_contains_bing_count}/{total} ({plan_rate:.1f}%)\")\n",
    "\n",
    "print(f\"\\nâ±ï¸ TIMING STATISTICS\")\n",
    "print(f\"   Total time: {total_time:.2f}s\")\n",
    "print(f\"   Average: {avg_time:.2f}s\")\n",
    "print(f\"   Min: {min_time:.2f}s\")\n",
    "print(f\"   Max: {max_time:.2f}s\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ SUMMARY ANALYSIS\")\n",
    "if pass_rate == 100:\n",
    "    print(\"ðŸŽ‰ All evaluations passed! Bing Grounding is working correctly.\")\n",
    "elif bing_rate < 100:\n",
    "    print(\"âš ï¸ Bing Grounding was not called in all iterations - check tool_choice settings.\")\n",
    "elif pass_rate >= 80:\n",
    "    print(\"âš ï¸ Most evaluations passed, but some inconsistencies detected.\")\n",
    "else:\n",
    "    print(\"âŒ Evaluation failed - Bing Grounding may not be returning current info.\")\n",
    "\n",
    "# Save results\n",
    "csv_file = \"bing_grounding_evaluation_results.csv\"\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"\\nðŸ’¾ Results saved to: {csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
