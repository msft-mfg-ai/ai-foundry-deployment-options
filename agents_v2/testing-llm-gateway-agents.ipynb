{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Agents v2 in AI Foundry\n",
    "This notebook creates and runs an agent from AI Foundry\n",
    "\n",
    "Best way to set it up is with [uv](https://docs.astral.sh/uv/)\n",
    "\n",
    "1. in `agents` directory run `uv sync` (if python is missing, install it using `uv python install`)\n",
    "2. in VSCode press [Ctrl+Shift+P] and select `Python: Select Interpreter`, choose the one from `agents` directory: `./agents/.venv/bin/python3.xx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Create Project client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import atexit\n",
    "import jsonref\n",
    "import os\n",
    "from azure.identity.aio import DefaultAzureCredential, AzureDeveloperCliCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    MCPTool,\n",
    "    Tool,\n",
    ")\n",
    "from openai.types.responses.response_input_param import (\n",
    "    McpApprovalResponse,\n",
    "    ResponseInputParam,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "from src.agents_utils import agents_utils\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "print(\"üöÄ Initializing AI Foundry Agent Testing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_AI_FOUNDRY_CONNECTION_STRING\")\n",
    "deployment_name = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\", None)\n",
    "tenant_id = os.environ.get(\"AZURE_TENANT_ID\", None)\n",
    "\n",
    "print(\"\\nüìã Configuration:\")\n",
    "print(f\"   üìç Endpoint: {endpoint[:50]}...\" if endpoint else \"   ‚ö†Ô∏è Endpoint: Not set\")\n",
    "print(f\"   ü§ñ Model: {deployment_name}\" if deployment_name else \"   ‚ö†Ô∏è Model: Not set\")\n",
    "print(f\"   üì¶ API Version: {api_version or 'Default'}\")\n",
    "\n",
    "ai_agent_settings = {\n",
    "    \"endpoint\": endpoint,\n",
    "    \"model_deployment_name\": deployment_name,\n",
    "    \"api_version\": api_version,\n",
    "}\n",
    "\n",
    "# Setup credentials\n",
    "print(\"\\nüîê Setting up authentication...\")\n",
    "if os.environ.get(\"USE_AZURE_DEV_CLI\") == \"true\":\n",
    "    print(\"   ‚úÖ Using Azure Developer CLI Credential\")\n",
    "    creds = AzureDeveloperCliCredential(tenant_id=tenant_id)\n",
    "else:\n",
    "    print(\"   ‚úÖ Using Default Azure Credential\")\n",
    "    creds = DefaultAzureCredential()\n",
    "\n",
    "await creds.__aenter__()\n",
    "print(\"   üîì Credentials initialized successfully!\")\n",
    "\n",
    "# Initialize clients\n",
    "print(\"\\nüîß Initializing clients...\")\n",
    "client = AIProjectClient(endpoint=endpoint, credential=creds)\n",
    "await client.__aenter__()\n",
    "agents_client = agents_utils(client)\n",
    "print(\"   ‚úÖ AI Project Client ready\")\n",
    "print(\"   ‚úÖ Agents Client ready\")\n",
    "\n",
    "# List connections\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîó AVAILABLE CONNECTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model_gateway_connection_static = None\n",
    "model_gateway_connection_dynamic = None\n",
    "ai_gateway_connection_static = None\n",
    "ai_gateway_connection_dynamic = None\n",
    "\n",
    "connection_count = 0\n",
    "async for connection in client.connections.list():\n",
    "    connection_count += 1\n",
    "    icon = (\n",
    "        \"üåê\"\n",
    "        if connection.type == \"ModelGateway\"\n",
    "        else \"üîå\" if connection.type == \"ApiManagement\" else \"üì°\"\n",
    "    )\n",
    "    default_badge = \" ‚≠ê DEFAULT\" if connection.is_default else \"\"\n",
    "    print(f\"\\n{icon} {connection.name}{default_badge}\")\n",
    "    print(f\"   Type: {connection.type}\")\n",
    "    print(f\"   ID: {connection.id[:50]}...\")\n",
    "\n",
    "    if connection.type == \"ModelGateway\" and \"static\" in connection.name.lower():\n",
    "        model_gateway_connection_static = connection.name\n",
    "        print(\"   üìå ‚Üí Assigned to: model_gateway_connection_static\")\n",
    "    if connection.type == \"ModelGateway\" and \"static\" not in connection.name.lower():\n",
    "        model_gateway_connection_dynamic = connection.name\n",
    "        print(\"   üìå ‚Üí Assigned to: model_gateway_connection_dynamic\")\n",
    "    if connection.type == \"ApiManagement\" and \"static\" in connection.name.lower():\n",
    "        ai_gateway_connection_static = connection.name\n",
    "        print(\"   üìå ‚Üí Assigned to: ai_gateway_connection_static\")\n",
    "    if connection.type == \"ApiManagement\" and \"static\" not in connection.name.lower():\n",
    "        ai_gateway_connection_dynamic = connection.name\n",
    "        print(\"   üìå ‚Üí Assigned to: ai_gateway_connection_dynamic\")\n",
    "\n",
    "print(f\"\\nüìä Total connections found: {connection_count}\")\n",
    "\n",
    "# List agents\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ü§ñ EXISTING AGENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "agents = await agents_client.get_agents()\n",
    "if agents:\n",
    "    for agent in agents:\n",
    "        print(f\"\\nü§ñ {agent.name}\")\n",
    "        print(f\"   ID: {agent.id}\")\n",
    "        print(f\"   Version: {agent.versions.latest.version}\")\n",
    "else:\n",
    "    print(\"\\n   ‚ÑπÔ∏è No agents found in this project\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ SETUP COMPLETE - Connection Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(\n",
    "    f\"   üåê Model Gateway (Static):  {'‚úÖ ' + model_gateway_connection_static if model_gateway_connection_static else '‚ùå Not found'}\"\n",
    ")\n",
    "print(\n",
    "    f\"   üåê Model Gateway (Dynamic): {'‚úÖ ' + model_gateway_connection_dynamic if model_gateway_connection_dynamic else '‚ùå Not found'}\"\n",
    ")\n",
    "print(\n",
    "    f\"   üîå AI Gateway (Static):     {'‚úÖ ' + ai_gateway_connection_static if ai_gateway_connection_static else '‚ùå Not found'}\"\n",
    ")\n",
    "print(\n",
    "    f\"   üîå AI Gateway (Dynamic):    {'‚úÖ ' + ai_gateway_connection_dynamic if ai_gateway_connection_dynamic else '‚ùå Not found'}\"\n",
    ")\n",
    "print(\"\\nüéâ Ready to run agent tests!\")\n",
    "\n",
    "\n",
    "async def cleanup():\n",
    "    \"\"\"Close all async clients properly\"\"\"\n",
    "    try:\n",
    "        await client.close()\n",
    "    except Exception:\n",
    "        await client.__aexit__(None, None, None)\n",
    "    try:\n",
    "        await creds.close()\n",
    "    except Exception:\n",
    "        await creds.__aexit__(None, None, None)\n",
    "    print(\"üßπ Clients closed\")\n",
    "\n",
    "\n",
    "def sync_cleanup():\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            loop.create_task(cleanup())\n",
    "        else:\n",
    "            loop.run_until_complete(cleanup())\n",
    "    except Exception:\n",
    "        print(\"‚ö†Ô∏è Cleanup failed\")\n",
    "        pass\n",
    "\n",
    "\n",
    "atexit.register(sync_cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple requests for each gateway connection and capture request IDs\n",
    "import pandas as pd\n",
    "from openai import APIStatusError, APIError\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "print(\"üß™ GATEWAY CONNECTION TESTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing each gateway connection with multiple requests to verify\")\n",
    "print(\"connectivity and capture request IDs for debugging.\\n\")\n",
    "\n",
    "# Collect all gateway connections to test\n",
    "gateway_connections = {\n",
    "    \"model_gateway_static\": model_gateway_connection_static,\n",
    "    \"model_gateway_dynamic\": model_gateway_connection_dynamic,\n",
    "    \"ai_gateway_static\": ai_gateway_connection_static,\n",
    "    \"ai_gateway_dynamic\": ai_gateway_connection_dynamic,\n",
    "}\n",
    "deployment_model: str = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Filter out None connections\n",
    "active_connections = {k: v for k, v in gateway_connections.items() if v is not None}\n",
    "print(f\"üìä Found {len(active_connections)} active connections to test:\")\n",
    "for name in active_connections.keys():\n",
    "    print(f\"   ‚Ä¢ {name}\")\n",
    "\n",
    "results = []\n",
    "num_requests = 5\n",
    "delete_agent_before_create = False\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Test Configuration:\")\n",
    "print(f\"   ‚Ä¢ Requests per connection: {num_requests}\")\n",
    "print(f\"   ‚Ä¢ Model: {deployment_model}\")\n",
    "print(f\"   ‚Ä¢ Delete agent before create: {delete_agent_before_create}\")\n",
    "\n",
    "for conn_name, conn_value in active_connections.items():\n",
    "    print(f\"\\n{'‚îÄ' * 60}\")\n",
    "    print(f\"üîÑ Testing: {conn_name}\")\n",
    "    print(f\"   Connection: {conn_value}\")\n",
    "    print(f\"{'‚îÄ' * 60}\")\n",
    "\n",
    "    for i in range(num_requests):\n",
    "        request_id = None\n",
    "        result = None\n",
    "        error_msg = None\n",
    "\n",
    "        try:\n",
    "            agent_name = f\"TestAgent_{conn_name}\".replace(\" \", \"-\").replace(\"_\", \"-\")[\n",
    "                :63\n",
    "            ]\n",
    "\n",
    "            # Create agent for this connection\n",
    "            print(f\"   üìù Request {i+1}/{num_requests}: Creating agent...\", end=\" \")\n",
    "            agent = await agents_client.create_agent(\n",
    "                name=agent_name,\n",
    "                model_gateway_connection=conn_value,\n",
    "                deployment_name=deployment_model,\n",
    "                delete_before_create=delete_agent_before_create,\n",
    "            )\n",
    "\n",
    "            openai_client = client.get_openai_client()\n",
    "\n",
    "            # Create conversation\n",
    "            conversation = await openai_client.conversations.create(\n",
    "                items=[\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"What is 2 + {i}? Reply with just the number.\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # Get response\n",
    "            response = await openai_client.responses.create(\n",
    "                conversation=conversation.id,\n",
    "                extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "                input=\"\",\n",
    "            )\n",
    "\n",
    "            # Extract request ID from response\n",
    "            request_id = response._request_id\n",
    "            result = \"SUCCESS\"\n",
    "            output = response.output_text[:50] if response.output_text else \"No output\"\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Connection\": conn_name,\n",
    "                    \"Model\": deployment_model,\n",
    "                    \"Request #\": i + 1,\n",
    "                    \"Request ID\": request_id,\n",
    "                    \"Result\": result,\n",
    "                    \"Output\": output,\n",
    "                }\n",
    "            )\n",
    "            print(f\"‚úÖ SUCCESS\")\n",
    "            print(f\"      Response: {output}\")\n",
    "            print(f\"      Request ID: {request_id}\")\n",
    "\n",
    "        except (APIStatusError, APIError, HttpResponseError) as e:\n",
    "            request_id = (\n",
    "                e.response.headers.get(\"x-request-id\", \"N/A\")\n",
    "                if hasattr(e, \"response\")\n",
    "                else \"N/A\"\n",
    "            )\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Connection\": conn_name,\n",
    "                    \"Model\": deployment_model,\n",
    "                    \"Request #\": i + 1,\n",
    "                    \"Request ID\": request_id,\n",
    "                    \"Result\": result,\n",
    "                    \"Output\": error_msg,\n",
    "                }\n",
    "            )\n",
    "            print(f\"‚ùå ERROR\")\n",
    "            print(f\"      {error_msg}\")\n",
    "            print(f\"      Request ID: {request_id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Connection\": conn_name,\n",
    "                    \"Model\": deployment_model,\n",
    "                    \"Request #\": i + 1,\n",
    "                    \"Request ID\": \"N/A\",\n",
    "                    \"Result\": result,\n",
    "                    \"Output\": error_msg,\n",
    "                }\n",
    "            )\n",
    "            print(f\"‚ùå ERROR\")\n",
    "            print(f\"      {error_msg}\")\n",
    "\n",
    "# Create DataFrame and display results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä RESULTS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "csv_file = \"gateway_connection_test_results.csv\"\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"\\nüíæ Results saved to: {csv_file}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "summary = df.groupby([\"Connection\", \"Result\"]).size().unstack(fill_value=0)\n",
    "print(summary)\n",
    "\n",
    "# Calculate success rate\n",
    "total = len(results)\n",
    "successes = len([r for r in results if r[\"Result\"] == \"SUCCESS\"])\n",
    "success_rate = (successes / total * 100) if total > 0 else 0\n",
    "print(f\"\\nüéØ Overall Success Rate: {successes}/{total} ({success_rate:.1f}%)\")\n",
    "\n",
    "if success_rate == 100:\n",
    "    print(\"üéâ All tests passed!\")\n",
    "elif success_rate >= 50:\n",
    "    print(\"‚ö†Ô∏è Some tests failed - check the results above\")\n",
    "else:\n",
    "    print(\"‚ùå Most tests failed - investigate connection issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Foundry directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîó DIRECT FOUNDRY CALL\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Calling AI Foundry directly without agent abstraction\")\n",
    "print(f\"   üìç Connection: {model_gateway_connection_static}\")\n",
    "print(f\"   ü§ñ Model: {deployment_name}\")\n",
    "print()\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    model=f\"{model_gateway_connection_static}/{deployment_name}\",\n",
    "    input=\"I am going to Paris, what should I see? Keep your answer brief.\",\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Response received!\")\n",
    "print(f\"   üÜî Request ID: {response._request_id}\")\n",
    "print(\"\\nüí¨ Response:\")\n",
    "print(\"‚îÄ\" * 40)\n",
    "print(response.output_text)\n",
    "print(\"‚îÄ\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run agent using static gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ AGENT WITH STATIC GATEWAY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   üîó Connection: {ai_gateway_connection_static}\")\n",
    "print()\n",
    "\n",
    "print(\"üìù Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyV2Agent\",\n",
    "    model_gateway_connection=ai_gateway_connection_static,\n",
    "    delete_before_create=True,\n",
    ")\n",
    "print(f\"   ‚úÖ Agent created: {agent.name}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the size of Poland in square miles?\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"   üí¨ Conversation started: {conversation.id[:20]}...\")\n",
    "\n",
    "print(\"\\n‚è≥ Waiting for response...\")\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Response received!\")\n",
    "print(f\"   üÜî Response ID: {response.id}\")\n",
    "print(\"\\nüí¨ Output:\")\n",
    "print(\"‚îÄ\" * 40)\n",
    "print(response.output_text)\n",
    "print(\"‚îÄ\" * 40)\n",
    "print(f\"\\nüí∞ Usage: {response.to_dict()['usage']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run agent using dynamic gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ AGENT WITH DYNAMIC GATEWAY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   üîó Connection: {model_gateway_connection_dynamic}\")\n",
    "print()\n",
    "\n",
    "print(\"üìù Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyV2Agent\",\n",
    "    model_gateway_connection=model_gateway_connection_dynamic,\n",
    "    delete_before_create=True,\n",
    ")\n",
    "print(f\"   ‚úÖ Agent created: {agent.name}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the history of Warsaw? Keep it brief.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"   üí¨ Conversation started: {conversation.id[:20]}...\")\n",
    "\n",
    "print(\"\\n‚è≥ Waiting for response...\")\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Response received!\")\n",
    "print(\"\\nüí¨ Output:\")\n",
    "print(\"‚îÄ\" * 40)\n",
    "print(response.output_text)\n",
    "print(\"‚îÄ\" * 40)\n",
    "print(f\"\\nüí∞ Usage: {response.to_dict()['usage']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üåä STREAMING RESPONSE TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing real-time streaming of agent responses\")\n",
    "print()\n",
    "\n",
    "print(\"üìù Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyAgentGpt5Mini\",\n",
    "    model_gateway_connection=model_gateway_connection_dynamic,\n",
    "    delete_before_create=True,\n",
    ")\n",
    "print(f\"   ‚úÖ Agent: {agent.name}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me hi in 10 random languages.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"   üí¨ Conversation: {conversation.id[:20]}...\")\n",
    "\n",
    "# Create streaming response\n",
    "response_stream_events = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"\\nüåä Streaming response:\")\n",
    "print(\"‚îÄ\" * 40)\n",
    "events_received = []\n",
    "\n",
    "async for event in response_stream_events:\n",
    "    previous_event = events_received[-1] if len(events_received) > 0 else None\n",
    "    if previous_event and previous_event[\"type\"] == event.type:\n",
    "        previous_event[\"count\"] += 1\n",
    "    else:\n",
    "        events_received.append({\"type\": event.type, \"count\": 1})\n",
    "\n",
    "    if event.type == \"response.created\":\n",
    "        print(f\"üÜï Stream started (ID: {event.response.id})\\n\")\n",
    "    elif event.type == \"response.output_text.delta\":\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "    elif event.type == \"response.text.done\":\n",
    "        print(\"\\n\" + \"‚îÄ\" * 40)\n",
    "        print(\"‚úÖ Text complete\")\n",
    "    elif event.type == \"response.completed\":\n",
    "        print(f\"\\nüéâ Response completed!\")\n",
    "        print(f\"üí∞ Usage: {event.response.to_dict()['usage']}\")\n",
    "\n",
    "print(\"\\nüìä Events received:\")\n",
    "for index, event in enumerate(events_received):\n",
    "    print(f\"   {index+1}. {event['type']} (√ó{event['count']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents_utils import process_stream\n",
    "from openai import NOT_GIVEN\n",
    "\n",
    "print(\"üîß STREAMING MCP TOOL CALLS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing MCP tool integration with streaming responses\")\n",
    "print()\n",
    "\n",
    "# Configure MCP tool\n",
    "mcp_tool = MCPTool(\n",
    "    server_label=\"ms-learn\",\n",
    "    server_url=\"https://learn.microsoft.com/api/mcp\",\n",
    "    require_approval=\"always\",\n",
    ")\n",
    "print(\"üîå MCP Tool configured:\")\n",
    "print(f\"   Label: {mcp_tool.server_label}\")\n",
    "print(f\"   URL: {mcp_tool.server_url}\")\n",
    "print(f\"   Approval: {mcp_tool.require_approval}\")\n",
    "\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "print(\"\\nüìù Creating agent with tools...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyAgentGpt5MiniTools\",\n",
    "    model_gateway_connection=model_gateway_connection_static,\n",
    "    delete_before_create=True,\n",
    "    instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "    tools=tools,\n",
    ")\n",
    "print(f\"   ‚úÖ Agent: {agent.name}\")\n",
    "print(f\"   ü§ñ Model: {agent.versions.latest.definition.model}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Find me learning paths on Microsoft Learn about Azure AI services.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"   üí¨ Conversation: {conversation.id[:20]}...\")\n",
    "\n",
    "# Streaming loop with tool approval\n",
    "events_received = []\n",
    "input_list = []\n",
    "response_id = None\n",
    "input = \"\"\n",
    "request_count = 0\n",
    "\n",
    "print(\"\\nüîÑ Starting tool call loop...\")\n",
    "print(\"‚îÄ\" * 60)\n",
    "\n",
    "while True:\n",
    "    response_stream_events = await openai_client.responses.create(\n",
    "        conversation=conversation.id if response_id is None else NOT_GIVEN,\n",
    "        previous_response_id=response_id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "        input=input,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüåä Stream iteration #{request_count + 1}:\")\n",
    "    events_received, input_list, response_id, full_response = await process_stream(\n",
    "        response_stream_events\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìä Events in this iteration:\")\n",
    "    for index, event in enumerate(events_received):\n",
    "        print(f\"   {index+1}. {event['type']} (√ó{event['count']})\")\n",
    "\n",
    "    if len(input_list) == 0:\n",
    "        break\n",
    "\n",
    "    input = input_list\n",
    "    print(f\"\\n‚úÖ Auto-approving {len(input_list)} tool request(s)...\")\n",
    "    request_count += 1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ Tool call loop completed!\")\n",
    "print(f\"   Total iterations: {request_count + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Streaming MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents_utils import process_response\n",
    "\n",
    "print(\"üîß NON-STREAMING MCP TOOL CALLS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing MCP tools without streaming (synchronous)\")\n",
    "print()\n",
    "\n",
    "# Configure MCP tool\n",
    "mcp_tool = MCPTool(\n",
    "    server_label=\"docs\",\n",
    "    server_url=\"https://gitmcp.io/Azure/azure-rest-api-specs\",\n",
    "    require_approval=\"always\",\n",
    ")\n",
    "print(f\"üîå MCP Tool configured:\")\n",
    "print(f\"   Label: {mcp_tool.server_label}\")\n",
    "print(f\"   URL: {mcp_tool.server_url}\")\n",
    "\n",
    "# Load OpenAPI spec (optional - not used in this example)\n",
    "with open(\"weather.json\", \"r\") as f:\n",
    "    openapi_weather = jsonref.loads(f.read())\n",
    "    openapi_weather[\"servers\"] = [{\"url\": \"https://wttr.in\"}]\n",
    "print(f\"üå§Ô∏è Weather OpenAPI spec loaded (available if needed)\")\n",
    "\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "print(\"\\nüìù Creating agent with tools...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MyAgentGpt5MiniTools\",\n",
    "    model_gateway_connection=model_gateway_connection_static,\n",
    "    delete_before_create=True,\n",
    "    instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "    tools=tools,\n",
    ")\n",
    "print(f\"   ‚úÖ Agent: {agent.name}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "response_id = None\n",
    "input = \"\"\n",
    "input_list: ResponseInputParam = []\n",
    "request_count = 0\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\"type\": \"message\", \"role\": \"user\", \"content\": \"Summarize the readme from attached MCP tool for me. Keep it very brief.\"}\n",
    "    ],\n",
    ")\n",
    "print(f\"   üí¨ Conversation: {conversation.id[:20]}...\")\n",
    "\n",
    "print(\"\\n‚è≥ Sending initial request...\")\n",
    "while True:\n",
    "    response = await openai_client.responses.create(\n",
    "        conversation=conversation.id if response_id is None else NOT_GIVEN,\n",
    "        previous_response_id=response_id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "        input=input,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüåä Stream iteration #{request_count + 1}:\")\n",
    "    events_received, input_list, response_id, full_response = await process_response(\n",
    "        response\n",
    "    )\n",
    "\n",
    "    print(\"\\nüìä Events in this iteration:\")\n",
    "    for index, event in enumerate(events_received):\n",
    "        print(f\"   {index+1}. {event['type']} (√ó{event['count']})\")\n",
    "\n",
    "    if len(input_list) == 0:\n",
    "        break\n",
    "\n",
    "    input = input_list\n",
    "    print(f\"\\n‚úÖ Auto-approving {len(input_list)} tool request(s)...\")\n",
    "    request_count += 1\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(response.output_text)\n",
    "print(\"\\nüí∞ Full response details:\")\n",
    "print(f\"   Usage: {response.to_dict().get('usage', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Agent MCP Loop Tests\n",
    "Run multiple requests using an agent with MCP tools and capture:\n",
    "- ‚úÖ Success/Error status for each iteration\n",
    "- üÜî Request IDs for debugging\n",
    "- üìä Summary statistics and success rate\n",
    "- üíæ Results exported to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import APIStatusError, APIError, NOT_GIVEN\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from src.agents_utils import process_response\n",
    "\n",
    "\n",
    "print(\"üîß MCP WITH AGENT - LOOP TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Running MCP tools with agent abstraction\")\n",
    "print(\"Testing with 10 iterations to capture errors and request IDs\")\n",
    "print()\n",
    "\n",
    "# Configure MCP tool\n",
    "mcp_tool = MCPTool(\n",
    "    server_label=\"weather\",\n",
    "    server_url=\"https://aca-mcp-qczp34j2qg7pk.ashyocean-7ea49412.westus.azurecontainerapps.io/mcp/mcp\",\n",
    "    require_approval=\"never\",\n",
    ")\n",
    "print(f\"üîå MCP Tool: {mcp_tool.server_label}\")\n",
    "print(f\"   URL: {mcp_tool.server_url}\")\n",
    "\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "# Create agent once at the top\n",
    "print(\"\\nüìù Creating agent...\")\n",
    "agent = await agents_client.create_agent(\n",
    "    name=\"MCPLoopTestAgent\",\n",
    "    # model_gateway_connection=model_gateway_connection_static,\n",
    "    deployment_name=\"gpt-5\",\n",
    "    delete_before_create=True,\n",
    "    instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "    tools=tools,\n",
    ")\n",
    "print(f\"   ‚úÖ Agent: {agent.name}\")\n",
    "print(f\"   ü§ñ Model: {agent.versions.latest.definition.model}\")\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "\n",
    "# Configuration\n",
    "num_iterations = 10\n",
    "results = []\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Test Configuration:\")\n",
    "print(f\"   ‚Ä¢ Iterations: {num_iterations}\")\n",
    "print(f\"   ‚Ä¢ Agent: {agent.name}\")\n",
    "print()\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    print(f\"\\n{'‚îÄ' * 60}\")\n",
    "    print(f\"üîÑ Iteration {iteration + 1}/{num_iterations}\")\n",
    "    print(f\"{'‚îÄ' * 60}\")\n",
    "    \n",
    "    request_id = None\n",
    "    result_status = None\n",
    "    error_msg = None\n",
    "    output_text = None\n",
    "    \n",
    "    try:\n",
    "        # Create new conversation for each iteration\n",
    "        random_number_a = iteration * 7 + 3\n",
    "        random_number_b = iteration * 11 + 5\n",
    "        conversation = await openai_client.conversations.create(\n",
    "            items=[\n",
    "                {\"type\": \"message\", \"role\": \"user\", \"content\": f\"Add {random_number_a} and {random_number_b} using MCP tool.\"}\n",
    "            ],\n",
    "        )\n",
    "        print(f\"   üí¨ Conversation: {conversation.id[:20]}...\")\n",
    "        response_id = None\n",
    "        input = \"\"\n",
    "        input_list: ResponseInputParam = []\n",
    "        request_count = 0\n",
    "\n",
    "        while True:\n",
    "            print(\"   ‚è≥ Sending request...\")\n",
    "            response = await openai_client.responses.create(\n",
    "                conversation=conversation.id if response_id is None else NOT_GIVEN,\n",
    "                previous_response_id=response_id,\n",
    "                extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "                input=input,\n",
    "            )\n",
    "\n",
    "            print(f\"\\nüåä Request iteration #{request_count + 1}:\")\n",
    "            events_received, input_list, response_id, full_response = await process_response(\n",
    "                response\n",
    "            )\n",
    "\n",
    "            if len(input_list) == 0:\n",
    "                break\n",
    "\n",
    "            input = input_list\n",
    "            print(f\"\\n‚úÖ Auto-approving {len(input_list)} tool request(s)...\")\n",
    "            request_count += 1\n",
    "\n",
    "\n",
    "        request_id = response._request_id\n",
    "\n",
    "        result_status = \"SUCCESS\"\n",
    "        output_text = response.output_text[:100] if response.output_text else \"No output\"\n",
    "        print(f\"   ‚úÖ SUCCESS\")\n",
    "        print(f\"      Request ID: {request_id}\")\n",
    "        print(f\"      Output: {output_text[:50]}...\")\n",
    "\n",
    "    except (APIStatusError, APIError, HttpResponseError) as e:\n",
    "        request_id = (\n",
    "            e.response.headers.get(\"x-request-id\", \"N/A\")\n",
    "            if hasattr(e, \"response\") and e.response is not None\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        result_status = \"ERROR\"\n",
    "        error_msg = str(e)\n",
    "        print(f\"   ‚ùå ERROR\")\n",
    "        print(f\"      Request ID: {request_id}\")\n",
    "        print(f\"      Error: {error_msg}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        result_status = \"ERROR\"\n",
    "        error_msg = str(e)\n",
    "        print(f\"   ‚ùå ERROR\")\n",
    "        print(f\"      Request ID: N/A\")\n",
    "        print(f\"      Error: {error_msg}\")\n",
    "\n",
    "    # Record results\n",
    "    results.append({\n",
    "        \"Iteration\": iteration + 1,\n",
    "        \"Request ID\": request_id or \"N/A\",\n",
    "        \"Result\": result_status,\n",
    "        \"Output/Error\": output_text if result_status == \"SUCCESS\" else error_msg,\n",
    "    })\n",
    "\n",
    "# Create DataFrame and display results\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä RESULTS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "csv_file = \"mcp_agent_test_results.csv\"\n",
    "df_results.to_csv(csv_file, index=False)\n",
    "print(f\"\\nüíæ Results saved to: {csv_file}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "total = len(results)\n",
    "successes = len([r for r in results if r[\"Result\"] == \"SUCCESS\"])\n",
    "errors = len([r for r in results if r[\"Result\"] == \"ERROR\"])\n",
    "success_rate = (successes / total * 100) if total > 0 else 0\n",
    "\n",
    "print(f\"   ‚úÖ Successes: {successes}\")\n",
    "print(f\"   ‚ùå Errors: {errors}\")\n",
    "print(f\"   üéØ Success Rate: {success_rate:.1f}%\")\n",
    "\n",
    "if success_rate == 100:\n",
    "    print(\"\\nüéâ All tests passed!\")\n",
    "elif success_rate >= 50:\n",
    "    print(\"\\n‚ö†Ô∏è Some tests failed - check the results above\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Most tests failed - investigate connection issues\")\n",
    "\n",
    "# Display unique request IDs for debugging\n",
    "print(\"\\nüìã Request IDs:\")\n",
    "for r in results:\n",
    "    status_icon = \"‚úÖ\" if r[\"Result\"] == \"SUCCESS\" else \"‚ùå\"\n",
    "    print(f\"   {status_icon} #{r['Iteration']}: {r['Request ID']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
