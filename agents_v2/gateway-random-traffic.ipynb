{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random model traffic with v2 Agents in Foundry\n",
    "This notebook creates and runs an agent from AI Foundry\n",
    "\n",
    "Best way to set it up is with [uv](https://docs.astral.sh/uv/)\n",
    "\n",
    "1. in `agents` directory run `uv sync` (if python is missing, install it using `uv python install`)\n",
    "2. in VSCode press [Ctrl+Shift+P] and select `Python: Select Interpreter`, choose the one from `agents` directory: `./agents/.venv/bin/python3.xx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Get projects from foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from src.foundry_utils import get_ai_foundry_projects\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "print(\"üöÄ Initializing AI Foundry Random Traffic Generator...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "deployments = [\"gpt-4.1-mini\", \"gpt-5-mini\", \"o3-mini\"]\n",
    "subscription_id = os.environ.get(\"AZURE_AI_FOUNDRY_SUBSCRIPTION_ID\")\n",
    "resource_group = os.environ.get(\"AZURE_AI_FOUNDRY_RESOURCE_GROUP\")\n",
    "account_name = os.environ.get(\"AZURE_AI_FOUNDRY_NAME\")\n",
    "\n",
    "print(\"\\nüìã Configuration:\")\n",
    "print(f\"   üìç Subscription: {subscription_id[:20]}...\" if subscription_id else \"   ‚ö†Ô∏è Subscription: Not set\")\n",
    "print(f\"   üì¶ Resource Group: {resource_group}\" if resource_group else \"   ‚ö†Ô∏è Resource Group: Not set\")\n",
    "print(f\"   üè≠ Account Name: {account_name}\" if account_name else \"   ‚ö†Ô∏è Account Name: Not set\")\n",
    "print(f\"   ü§ñ Available Models: {', '.join(deployments)}\")\n",
    "\n",
    "# Get all project endpoints\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîç DISCOVERING PROJECTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_endpoints = await get_ai_foundry_projects(\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group=resource_group,\n",
    "    account_name=account_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Found {len(project_endpoints)} project endpoint(s)\")\n",
    "\n",
    "# Create AIProjectClient and agents_utils for each project\n",
    "print(\"\\nüîß Initializing clients...\")\n",
    "project_clients: list[AIProjectClient] = []\n",
    "creds = DefaultAzureCredential()\n",
    "\n",
    "for idx, endpoint in enumerate(project_endpoints):\n",
    "    if endpoint:\n",
    "        project_client = AIProjectClient(endpoint=endpoint, credential=creds)\n",
    "        await project_client.__aenter__()\n",
    "        project_clients.append(project_client)\n",
    "        print(f\"   ‚úÖ Client {idx + 1}: {endpoint[:50]}...\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ SETUP COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   üìä Total clients created: {len(project_clients)}\")\n",
    "print(f\"   ü§ñ Models to test: {len(deployments)}\")\n",
    "print(\"\\nüéâ Ready to generate random traffic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send random requests to random models for each project\n",
    "from src.foundry_utils import get_gateway_connections, classify_connection\n",
    "from src.agents_utils import agents_utils, create_response_with_retry\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from openai import APIStatusError, APIError\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "print(\"üé≤ RANDOM TRAFFIC GENERATOR\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Sending randomized requests across projects and models\")\n",
    "print()\n",
    "\n",
    "# Seed random with current time to ensure different values each run\n",
    "random.seed(time.time())\n",
    "\n",
    "# Configuration\n",
    "min_requests_per_project = 3\n",
    "max_requests_per_project = 10\n",
    "prompts = [\n",
    "    \"What is 2 + 2?\",\n",
    "    \"Tell me a joke\",\n",
    "    \"What's the capital of France?\",\n",
    "    \"Explain quantum computing in one sentence\",\n",
    "    \"What is the meaning of life?\",\n",
    "    \"Write a haiku about coding\",\n",
    "    \"What color is the sky?\",\n",
    "    \"Name three programming languages\",\n",
    "]\n",
    "\n",
    "print(\"‚öôÔ∏è Test Configuration:\")\n",
    "print(f\"   ‚Ä¢ Min requests per project: {min_requests_per_project}\")\n",
    "print(f\"   ‚Ä¢ Max requests per project: {max_requests_per_project}\")\n",
    "print(f\"   ‚Ä¢ Available prompts: {len(prompts)}\")\n",
    "print(f\"   ‚Ä¢ Available models: {', '.join(deployments)}\")\n",
    "print()\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, project_client in enumerate(project_clients):\n",
    "    endpoint = project_endpoints[idx]\n",
    "    num_requests = random.randint(min_requests_per_project, max_requests_per_project)\n",
    "    \n",
    "    print(f\"\\n{'‚îÄ' * 60}\")\n",
    "    print(f\"üìÅ PROJECT {idx + 1}/{len(project_clients)}\")\n",
    "    print(f\"{'‚îÄ' * 60}\")\n",
    "    print(f\"   üìç Endpoint: {endpoint[:50]}...\" if endpoint else \"   ‚ö†Ô∏è Endpoint: Unknown\")\n",
    "    \n",
    "    gateway_connections = await get_gateway_connections(project_client)\n",
    "    print(\"   üîë Gateway Connections Found:\")\n",
    "    for key, value in gateway_connections.items():\n",
    "        print(f\"      ‚Ä¢ {key}: {value}\")\n",
    "    agents_client = agents_utils(project_client)\n",
    "    \n",
    "    # Get all available (non-None) connections and randomly select from them\n",
    "    available_connections = [v for v in gateway_connections.values() if v]\n",
    "    \n",
    "    if not available_connections:\n",
    "        print(f\"   ‚ö†Ô∏è Skipping - no gateway connection found\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"   üé≤ Available connections: {len(available_connections)}\")\n",
    "    print(f\"   üìä Requests planned: {num_requests}\")\n",
    "\n",
    "    openai_client = project_client.get_openai_client()\n",
    "    print()\n",
    "\n",
    "    for i in range(num_requests):\n",
    "        # Pick random model, prompt, and connection\n",
    "        model = random.choice(deployments)\n",
    "        prompt = random.choice(prompts)\n",
    "        connection_name = random.choice(available_connections)\n",
    "        gateway_type, mode = classify_connection(connection_name, gateway_connections)\n",
    "        request_id = None\n",
    "        result = None\n",
    "        error_msg = None\n",
    "        output = None\n",
    "\n",
    "        try:\n",
    "            agent = await agents_client.create_agent(\n",
    "                name=\"temp-agent\",\n",
    "                model_gateway_connection=connection_name,\n",
    "                deployment_name=model,\n",
    "                delete_before_create=False,\n",
    "            )\n",
    "\n",
    "            # Create conversation\n",
    "            conversation = await openai_client.conversations.create(\n",
    "                items=[\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # Get response\n",
    "            response = await create_response_with_retry(openai_client, conversation, agent)\n",
    "\n",
    "            request_id = response._request_id\n",
    "            result = \"SUCCESS\"\n",
    "            output = response.output_text[:100] if response.output_text else \"No output\"\n",
    "\n",
    "            print(f\"   ‚úÖ [{i+1}/{num_requests}] {model} via {gateway_type}/{mode} ‚Üí {output[:40]}...\")\n",
    "\n",
    "        except (APIStatusError, APIError, HttpResponseError) as e:\n",
    "            request_id = (\n",
    "                e.response.headers.get(\"x-request-id\", \"N/A\")\n",
    "                if hasattr(e, \"response\") and e.response\n",
    "                else \"N/A\"\n",
    "            )\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "            output = error_msg\n",
    "            print(f\"   ‚ùå [{i+1}/{num_requests}] {model} via {gateway_type}/{mode} ‚Üí {error_msg}...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "            output = error_msg\n",
    "            print(f\"   ‚ùå [{i+1}/{num_requests}] {model} via {gateway_type}/{mode} ‚Üí {error_msg}...\")\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"Project\": endpoint.split(\"/\")[-1] if endpoint else f\"Project_{idx}\",\n",
    "                \"Connection\": connection_name if connection_name else \"N/A\",\n",
    "                \"GatewayType\": gateway_type,\n",
    "                \"Mode\": mode,\n",
    "                \"Model\": model,\n",
    "                \"Request #\": i + 1,\n",
    "                \"Request ID\": request_id or \"N/A\",\n",
    "                \"Prompt\": prompt[:30] + \"...\" if len(prompt) > 30 else prompt,\n",
    "                \"Result\": result,\n",
    "                \"Output\": output[:50] if output else \"N/A\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Create DataFrame and display results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä RESULTS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(df[[\"Project\", \"GatewayType\", \"Mode\", \"Model\", \"Result\", \"Output\"]].to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "csv_file = \"gateway_random_traffic_results.csv\"\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"\\nüíæ Results saved to: {csv_file}\")\n",
    "\n",
    "# Summary by Gateway Type (APIM vs ModelGateway)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà SUMMARY BY GATEWAY TYPE (APIM vs ModelGateway)\")\n",
    "print(\"=\" * 60)\n",
    "gateway_summary = df.groupby([\"GatewayType\", \"Result\"]).size().unstack(fill_value=0)\n",
    "if \"SUCCESS\" not in gateway_summary.columns:\n",
    "    gateway_summary[\"SUCCESS\"] = 0\n",
    "if \"ERROR\" not in gateway_summary.columns:\n",
    "    gateway_summary[\"ERROR\"] = 0\n",
    "gateway_summary[\"Total\"] = gateway_summary[\"SUCCESS\"] + gateway_summary[\"ERROR\"]\n",
    "gateway_summary[\"Success Rate\"] = (gateway_summary[\"SUCCESS\"] / gateway_summary[\"Total\"] * 100).round(1).astype(str) + \"%\"\n",
    "print(gateway_summary)\n",
    "\n",
    "# Summary by Mode (static vs dynamic)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà SUMMARY BY MODE (Static vs Dynamic)\")\n",
    "print(\"=\" * 60)\n",
    "mode_summary = df.groupby([\"Mode\", \"Result\"]).size().unstack(fill_value=0)\n",
    "if \"SUCCESS\" not in mode_summary.columns:\n",
    "    mode_summary[\"SUCCESS\"] = 0\n",
    "if \"ERROR\" not in mode_summary.columns:\n",
    "    mode_summary[\"ERROR\"] = 0\n",
    "mode_summary[\"Total\"] = mode_summary[\"SUCCESS\"] + mode_summary[\"ERROR\"]\n",
    "mode_summary[\"Success Rate\"] = (mode_summary[\"SUCCESS\"] / mode_summary[\"Total\"] * 100).round(1).astype(str) + \"%\"\n",
    "print(mode_summary)\n",
    "\n",
    "# Combined summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà SUMMARY BY GATEWAY TYPE AND MODE\")\n",
    "print(\"=\" * 60)\n",
    "combined_summary = df.groupby([\"GatewayType\", \"Mode\", \"Result\"]).size().unstack(fill_value=0)\n",
    "if \"SUCCESS\" not in combined_summary.columns:\n",
    "    combined_summary[\"SUCCESS\"] = 0\n",
    "if \"ERROR\" not in combined_summary.columns:\n",
    "    combined_summary[\"ERROR\"] = 0\n",
    "combined_summary[\"Total\"] = combined_summary[\"SUCCESS\"] + combined_summary[\"ERROR\"]\n",
    "combined_summary[\"Success Rate\"] = (combined_summary[\"SUCCESS\"] / combined_summary[\"Total\"] * 100).round(1).astype(str) + \"%\"\n",
    "print(combined_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ OVERALL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "total = len(results)\n",
    "successes = len([r for r in results if r[\"Result\"] == \"SUCCESS\"])\n",
    "errors = len([r for r in results if r[\"Result\"] == \"ERROR\"])\n",
    "success_rate = (successes / total * 100) if total > 0 else 0\n",
    "\n",
    "print(f\"   ‚úÖ Successes: {successes}\")\n",
    "print(f\"   ‚ùå Errors: {errors}\")\n",
    "print(f\"   üéØ Success Rate: {success_rate:.1f}%\")\n",
    "\n",
    "if success_rate == 100:\n",
    "    print(\"\\nüéâ All requests completed successfully!\")\n",
    "elif success_rate >= 50:\n",
    "    print(\"\\n‚ö†Ô∏è Some requests failed - check the results above\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Most requests failed - investigate connection issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
